{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b69c0b-c9d0-4e6b-9705-f24cd3914bcf",
   "metadata": {},
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c88bd-678d-44e4-b778-8ecd955e9538",
   "metadata": {},
   "source": [
    "*¿Para qué se utiliza?*\n",
    "Los árboles de decisión son una técnica de machine learning supervisado que se utiliza tanto para clasificación (cuando la variable dependiente es categórica) como para regresión (cuando es continua). Son especialmente útiles para modelar procesos de toma de decisiones, identificar patrones en los datos y predecir resultados a partir de variables explicativas. Se aplican ampliamente en áreas como análisis de clientes, detección de fraude, segmentación de mercado y evaluación de riesgo crediticio.\n",
    "\n",
    "*¿Qué variables considera?*\n",
    "- Variable dependiente: En clasificación: variable categórica (por ejemplo, “compra” sí/no, tipo de cliente, nivel de riesgo). En regresión: variable numérica continua (por ejemplo, ventas, ingreso, puntuación).\n",
    "- Variables independientes: pueden ser categóricas o numéricas. El algoritmo decide cómo dividir los datos según los valores de estas variables para maximizar la separación entre clases o minimizar el error.\n",
    "\n",
    "*¿Cómo funciona?*\n",
    "Un árbol de decisión divide los datos en ramas jerárquicas basadas en condiciones lógicas sobre las variables independientes. Cada nodo interno representa una decisión basada en una variable, y cada hoja representa un resultado o predicción. \n",
    "\n",
    "El algoritmo elige las divisiones (\"cortes\") que mejor separan los datos usando criterios como:\n",
    "- Gini o Entropía para clasificación.\n",
    "- Varianza o error cuadrático para regresión.\n",
    "\n",
    "Este proceso se repite de forma recursiva hasta que se cumplen ciertos criterios de parada, como una profundidad máxima del árbol o un número mínimo de observaciones por hoja.\n",
    "\n",
    "*Supuestos y recomendaciones*\n",
    "- No requiere supuestos estadísticos como normalidad o igualdad de varianzas, lo que los hace muy flexibles.\n",
    "- Son sensibles al sobreajuste, especialmente si el árbol crece sin restricciones.\n",
    "\n",
    "Se recomienda aplicar técnicas como poda, establecer una profundidad máxima, o usar árboles ensemble (como Random Forest).\n",
    "- Los árboles pueden ser inestables: pequeñas variaciones en los datos pueden generar árboles muy diferentes. Por eso se suele preferir su uso combinado en algoritmos más robustos.\n",
    "- Son fáciles de interpretar y visualizar, lo cual los hace valiosos para explicar decisiones a personas no técnicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9670fbf-56c4-412a-a1ea-39cc2d78b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suponemos que tienes un DataFrame df con varias columnas independientes y una columna objetivo llamada 'y'\n",
    "# Por ejemplo:\n",
    "# df = pd.DataFrame({\n",
    "#     'edad': [25, 40, 35, 22, 50],\n",
    "#     'ingreso': [30000, 70000, 50000, 28000, 80000],\n",
    "#     'compra': [0, 1, 1, 0, 1]\n",
    "# })\n",
    "\n",
    "# Separar variables predictoras (X) y objetivo (y)\n",
    "X = df.drop(columns='y')  # Variables independientes\n",
    "y = df['y']               # Variable dependiente (clasificación binaria o multiclase)\n",
    "\n",
    "# División en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo\n",
    "modelo = DecisionTreeClassifier(max_depth=3, random_state=42)  # Puedes ajustar la profundidad\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación\n",
    "y_pred = modelo.predict(X_test)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualizar árbol\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(modelo, feature_names=X.columns, class_names=True, filled=True)\n",
    "plt.title(\"Árbol de decisión\")\n",
    "plt.show()\n",
    "\n",
    "# Matriz de confusión\n",
    "ConfusionMatrixDisplay.from_estimator(modelo, X_test, y_test, cmap='Blues')\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f36094-e3bb-4498-96ba-e002e9e1410f",
   "metadata": {},
   "source": [
    "Ejemplo de reporte de conclusiones\n",
    ">Se aplicó un árbol de decisión para predecir si un cliente realizará una compra (variable objetivo binaria), utilizando como variables predictoras la edad y el ingreso mensual. El modelo se entrenó con el 70% de los datos y se evaluó con el 30% restante. El árbol ajustado tuvo una profundidad máxima de 3, lo que permitió un equilibrio entre interpretabilidad y rendimiento. El modelo alcanzó una precisión general del 87%, con una sensibilidad del 90% para el grupo de compradores, lo que indica una buena capacidad para identificar clientes con alta probabilidad de compra. El árbol identificó como divisores clave el ingreso y la edad, siendo el ingreso el primer nodo de decisión. La visualización del árbol mostró reglas claras que pueden ser utilizadas para segmentar clientes en campañas de marketing dirigidas. La matriz de confusión confirmó un bajo número de falsos positivos y negativos, y se observó una importancia destacada del ingreso mensual como predictor principal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca7f9e-471c-4751-9691-1688f9d0c470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
