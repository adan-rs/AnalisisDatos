{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77143b4-62a7-47d5-ba7f-a508a9f1eee5",
   "metadata": {},
   "source": [
    "# Análisis de regresión\n",
    "\"*Todos los modelos están equivocados, pero algunos son útiles\" G.E.P. Box (1919-2013)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5b02f-47a1-41d7-9988-e59525ccdaad",
   "metadata": {},
   "source": [
    "## ¿Qué es el análisis de regresión lineal?\n",
    "\n",
    "El análisis de regresión lineal es una técnica que se utiliza para pronosticar o explicar el comportamiento de una variable *dependiente* con relación a una o más variables *independientes*. En el área de negocios, la variable dependiente generalmente es la variable que nos interesa explicar o pronosticar (por ejemplo *ventas*), mientras que las variables independientes son aquellas que nos sirven para explicar (por ejemplo *gasto en publicidad*).\n",
    "\n",
    "Se asume que esta relación se ajusta a una ecuación lineal conocida como ecuación de regresión. Cuando sólo se tiene una variable independiente se conoce como regresión lineal simple: \n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x  + \\varepsilon\n",
    "$$\n",
    "Donde $y$ es la variable dependiente y $x$ es la variable independiente y $\\varepsilon$ es el término de error. La interpretación de los resultados nos permitirá:\n",
    "\n",
    "- Evaluar si la variable independiente tiene un efecto significativo sobre la variable dependiente.\n",
    "- Evaluar la magnitud del efecto de la variable independiente sobre la dependiente.\n",
    "- Realizar predicciones con base en las variables independientes.\n",
    "\n",
    "El procedimiento más común para estimar esta ecuación de regresión es minimizando los errores al cuadrado en un método conocido como *mínimos cuadrados ordinarios*.\n",
    "\n",
    "Ejemplo: https://phet.colorado.edu/sims/html/least-squares-regression/latest/least-squares-regression_en.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ed06c-83e2-4c9a-bb0b-a4226070444a",
   "metadata": {},
   "source": [
    "### Interpretación de un modelo de regresión\n",
    "En su planteamiento básico la ecuación o modelo de regresión múltiple es la siguiente:\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 +...+ \\beta_k x_k + \\varepsilon\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $y$ es la variable dependiente.\n",
    "- $x$ es la variable independiente. Si solo existe una variable independiente se conoce como *regresión lineal simple*, si son dos o más, se llama *regresión lineal múltiple*.\n",
    "- $\\beta_0$ es el término de intersección (constante o intercepto), es el valor que tomaría $y$ si todas las variables fueran igual a cero (esto solo tiene sentido en algunos casos). \n",
    "- $\\beta_1$ es el coeficiente de regresión para cada $x$. Es el cambio estimado en la variable dependiente por unidad de cambio en la variable independiente, con todo lo demás constante.\n",
    "- $\\varepsilon$ es el término de error. Cuando corresponde al resultado de un modelo en específico es preferible referirse al error como *residual*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b2b7c-065d-4894-9e9f-765fc0ec00f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Supuestos básicos del modelo\n",
    "Las estimaciones de los coeficientes de regresión serán óptimas, de acuerdo al teorema de Gauss-Markov, si cumplen los siguientes supuestos con respecto al término de error:\n",
    "- El error sigue una distribución normal.\n",
    "- El error tenga media igual a cero.\n",
    "- Los errores son independientes (no están relacionados entre sí).\n",
    "- La varianza del error es constante.\n",
    "Esto se resume como que e~N<sub>iid</sub> (0,σ<sup>2</sup>). Si se cumplen estos supuestos, los estimadores serán los mejores estimadores insesgados de mínima varianza (*MELI* por las siglas en español; *BLUE* por las siglas en inglés). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5df22-995a-41f0-a2d4-4047a2ca88ac",
   "metadata": {},
   "source": [
    "## Análisis de regresión\n",
    "Utilizaremos un modelo de regresión para estimar el precio de una casa en una zona de la ciudad. Como primer paso importamos las bibliotecas a utilizar. En esta ocasión agregaremos la biblioteca warnings para evitar notificaciones de cambios futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85504c-8bff-4b4e-a2c9-6dbaa12ac32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bee3b9-8e78-41ad-981b-3459e2a42f28",
   "metadata": {},
   "source": [
    "### Características de la muestra\n",
    "Existen varias recomendaciones para determinar qué *tamaño de muestra* es adecuado. Para generalizar los resultados, lo mínimo recomendable son 5 observaciones por cada variable independiente, aunque lo deseable es tener de 15 a 20 observaciones por cada variable independiente  (Hair, Black, Babin, & Anderson, 2009).  \n",
    "Green (1991) considera inadecuado establecer una constante (p. ej. 100 observaciones) pero sugiere que para evaluar un modelo se deben tener 50+8*k* observaciones, donde *k* es el número de variables independientes. Si se desea evaluar los coeficientes de regresión de cada variable recomienda 104+*k* observaciones.  \n",
    "Finalmente, además del tamaño de la muestra, es importante asegurarse de que la muestra sea *representativa* de la población."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6181f8-5fe3-46ea-a1ca-ba844003f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el archivo \"data/b01_casas.xlsx\"\n",
    "df = pd.read_excel('data/b01_casas.xlsx')\n",
    "# Para este ejemplo seleccionamos casas (tipo = 0 )\n",
    "df = df[df['tipo']==0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d191c-fb3d-4d67-b8ef-4f13a64a2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar las variables y el número de observaciones\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88755fec-cf78-476d-89e7-50a0259c3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar las primeras filas del DataFrame\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7377cfd-9bfe-4622-9f3d-d3868f500a9d",
   "metadata": {},
   "source": [
    "### Características de las variables\n",
    "En el modelo de regresión lineal múltiple, la variable dependiente debe ser cuantitativa (con escala de medición de intervalo o de razón) y al menos una variable independiente también deberá ser cuantitativa.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fa5d3-b327-4637-89c5-528e94ff5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica las variables cuantitativasy obtener la estadística descriptiva\n",
    "var_cont = df[['preciomillones', 'recamaras', 'baños', 'construccion']]\n",
    "var_cont.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20ab8b-269a-4238-b426-03b5ca2a514f",
   "metadata": {},
   "source": [
    "Las variables independientes no deben presentar *multicolinealidad*, esto es, que una combinación lineal de dos o más variables contengan la misma información que otra variable independiente. Aunque hay análisis formales para ello, un primer acercamiento es tratar de evitar que existan altas correlaciones (r > 0.90) entre dos variables independientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27021f61-197f-4cca-a758-8528fd5cac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la matriz de correlaciones\n",
    "var_cont.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3083a27c-8224-40f3-9446-a73678dbcf89",
   "metadata": {},
   "source": [
    "La función `sns.pairplot`es útil para visualizar las relaciones entre pares de variables en un DataFrame. El primer parámetro indica el nombre del DataFrame, *corner* sirve para mostrar solo la matriz triangular inferior, *kind* permite indicar el tipo de gráfico (observa cómo cambia con 'reg' en vez de 'scatter'), *makers* se utiliza para indicar el tipo de marcas en el gráfico (observa cómo cambia con '+' en vez de '.'), y *height*  es la altura en pulgadas de cada gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557c9378-a199-4d7c-8d28-a5d4c3cf55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos las relaciones entre variables\n",
    "sns.pairplot(var_cont, corner=True, kind='reg', markers='+', height=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ac202-64b9-40d7-9bbb-7aa54aa5b0da",
   "metadata": {},
   "source": [
    "### Estimación del modelo (con StatsModels)\n",
    "Utilizaremos primero la biblioteca *StatsModels* para realizar el análisis de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7c6c2-2234-451e-9e8d-efc31b3c0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librería\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171e4b3-65dd-40a3-98a8-75fdb3be0ecb",
   "metadata": {},
   "source": [
    "Es recomendable crear un dataframe 'X' con las variables independientes y otro \"y\" con la variable dependiente. Para seleccionar las variables independientes primero evalúa cuáles pueden ser relevantes. Cuando se tienen muchas variables independientes se puede realizar un **Análisis Factorial** para reducir la dimensionalidad. Para este ejemplo, empezaremos con la variable \"construcción\". La opción de StatsModel que utilizaremos, requiere crear una columna de \"1\" para representar la constante en el modelo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f07f10-2b2b-4069-a1d6-a0a62e151ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con las v. indep. y la v. dependiente\n",
    "X = df[['construccion', 'baños']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['preciomillones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f289dc-9400-46d5-96ac-80f0e7f58d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d31f60e-c8a4-414b-9dcb-7001b1d801a9",
   "metadata": {},
   "source": [
    "Corremos el modelo de regresión mediante mínimos cuadrados ordinarios:  \n",
    "`regresion = sm.OLS(y, X).fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d766fbb-b19f-41ae-bb67-f98c8fd975af",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa841e6-bfc6-434f-af72-431c14e4d4ed",
   "metadata": {},
   "source": [
    "El resultado se muestra con la instrucción\n",
    "`summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620f5f5-a2bf-42f6-94f1-4f5eea1dc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb38446-06fc-4400-af27-f457071b6063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficientes de regresión\n",
    "regresion.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bbe5f-746b-4264-955c-c6d78cce888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuales\n",
    "residuales = regresion.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debdee7e-eac0-4145-bed1-2cb6586f5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores estimados\n",
    "y_hat = regresion.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8d571-d4e9-46bb-bd01-2773d0945cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pronóstico\n",
    "nuevos_valores = [1,500,2]\n",
    "regresion.predict(nuevos_valores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597425bf-d41a-4cbc-bace-e0378491bed0",
   "metadata": {},
   "source": [
    "## Interpretación de los resultados\n",
    "- R-squared: entre más cercano a 1 es mejor\n",
    "- Adj. R-squared: se utiliza para comparar modelos con diferente número de variables independientes, debido a que la R cuadrada ajustada penaliza el incluir variables no significativas.\n",
    "- AIC (Criterio de información de Akaike)/ BIC (Criterio de información Bayesiano): también son medidas relativas que se utilizan para comparar modelos de regresión múltiple e identificar el de mejor ajuste y simplicidad (menos es mejor).\n",
    "- F-statistic: evalúa la significancia del modelo en conjunto, la hipótesis nula es que todos los coeficientes de regresión son iguales a cero.\n",
    "- Skew: o *sesgo* es una medida de la asimetría de la distribución\n",
    "- Kurtosis: indica qué tan \"puntiaguda\" o \"achatada\" es una distribución.\n",
    "- Prob(Omnibus): es una prueba para evaluar la normalidad en los residuales.\n",
    "- Jarque-Bera(JB) es un estadístico que sirve para evaluar la normalidad en los residuales.\n",
    "- Durbin-Watson: sirve para evaluar la presencia de autocorrelación. Valores entre 0 y 2 indican una autocorrelación positiva y valores entre 2 y 4 indican una autocorrelación negativa. Valores cercanos a 2 son deseables.\n",
    "- Cond. No. es el número de condición, que sirve para evalur problemas de multicolinealidad. Valores arriba de 30 se consideran problemáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f33e7c-05e0-4b53-87e4-ce11867ef6d0",
   "metadata": {},
   "source": [
    "### Ajuste del modelo\n",
    "La métrica más utilizada para medir el ajuste del modelo es el *coeficiente de determinación* (R<sup>2</sup>) que mide la proporción de la variación de la variable dependiente que es explicada por el modelo. En un modelo de regresión lineal, la variación total de los datos  se mide con sumas de cuadrados:\n",
    "$$\n",
    "SS_{total} = SS_{modelo} + SS_{residual}\n",
    "$$\n",
    "Donde:\n",
    "\n",
    "$SS_{total} = \\sum_{i = 1}^{n} (y-\\bar{y})^2$ es la suma de cuadrados total  \n",
    "$SS_{modelo} = \\sum_{i = 1}^{n} (\\hat{y}-\\bar{y})^2$ es la suma de cuadrados del modelo también conocida como suma de cuadrados explicada  \n",
    "$SS_{residual} = \\sum_{i = 1}^{n} (y-\\hat{y})^2$ es la suma de cuadrados del residual o suma de cuadrados del error\n",
    "\n",
    "El coeficiente de determinación es equivalente a\n",
    "\n",
    "$$\n",
    "R^2 = SS_{modelo} / SS_{total}\n",
    "$$\n",
    "\n",
    "La R cuadrada toma valores entre 0 y 1, donde valores más grandes indican un mejor ajuste. Sin embargo, no existen criterios únicos de qué valor de R cuadrada es aceptable, sino que ello depende del área de estudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d1ce90-c60e-40c6-8f2d-2f647e011d6b",
   "metadata": {},
   "source": [
    "## Evaluación de supuestos\n",
    "### Homocedasticidad\n",
    "Uno de los supuestos del modelo de regresión es que la varianza de los residuales se mantiene constante (homocedasticidad). El cumplimiento de este supuesto se puede explorar en la gráfica del residual estandarizado versus $\\hat{Y}$. Por ejemplo, un patrón de dispersión creciente (o decreciente) indicaría una violación a este supuesto.\n",
    "\n",
    "Existen varias pruebas que se pueden realizar para evaluar la presencia de heteroscedasticidad, tales como:\n",
    "- Breusch-Pagan: calcula la relación entre los residuales al cuadrado y las variables independientes, si la relación es significativa indica heteroscedasticidad..\n",
    "- Prueba de White: similar a la Breush-Pagan, considera la correlación serial.\n",
    "- Prueba de Goldfeld-Quandt: divide los datos con base en los valores de una variable independiente y compara las varianzas de los residuales en ambos grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf773e65-15f8-4d70-92ae-19aec0b30b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de residuales\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.scatter(y_hat, residuales, marker='.', color='b')\n",
    "plt.xlabel('y hat')\n",
    "plt.ylabel('residuales');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3b162-4c0a-45fa-bb08-6f8d3f3dc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "# Asumiendo que ya se tiene el modelo y los residuales\n",
    "lm, lm_p_value, fvalue, f_p_value = het_breuschpagan(residuales, X)\n",
    "\n",
    "print(\"Estadístico LM:\", lm)\n",
    "print(\"Valor p del estadístico LM:\", lm_p_value)\n",
    "print(\"Estadístico F:\", fvalue)\n",
    "print(\"Valor p del estadístico F:\", f_p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc183c02-9ff9-4920-9388-068e3e5a3371",
   "metadata": {},
   "source": [
    "Si el p-valor es menor que 0.05 es evidencia de la presencia de heteroscedasticidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17e6cb-4ec9-437b-a636-ba6929f23ed0",
   "metadata": {},
   "source": [
    "*¿Qué hacer si se detecta heteroscedasticidad?*\n",
    "- Explorar transformaciones de variables (p. ej. logaritmos)\n",
    "- Utilizar otros modelos de regresión, como Mínimos Cuadrados Ponderados (WLS) que asigna pesos inversamente proporcionales a la varianza de los errores\n",
    "- Crear modelos separados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919bfaf-c92e-4e3e-a8ca-7061b0f00ed0",
   "metadata": {},
   "source": [
    "### Normalidad\n",
    "La normalidad en la distribución de los errores y su media se puede verificar en el histograma de los residuales y una prueba de normalidad (como Shapiro-Wilks o  Kolmogorov-Smirnov). En la prueba de normalidad lo deseable es obtener un p-valor mayor a 0.05 (no se rechaza la hipótesis nula de normalidad en los datos). \n",
    "\n",
    "El reporte de salida de StatsModelo muestra el p-valor de las pruebas omnibus y de Jarque-Bera, ambas basadas en el sesgo y la curtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df049f4-1857-4f6c-82ff-5d21a3cac07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3)) \n",
    "sns.histplot(residuales, color='b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f75edc-76ec-472f-b6b4-86826f430d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "stat, p_value = shapiro(residuales)\n",
    "print(\"Estadístico de prueba:\", stat)\n",
    "print(\"Valor p:\", p_value)\n",
    "\n",
    "# Interpretar los resultados\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Se rechaza la hipótesis nula de normalidad en los datos\")\n",
    "else:\n",
    "    print(\"No se puede rechazar la hipótesis nula de normalidad en los datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee2c61-b724-45c9-89a2-021dfb19b57c",
   "metadata": {},
   "source": [
    "*¿Qué hacer si se detecta no normalidad en los residuales?*\n",
    "\n",
    "- Revisar outliers o valores influyentes.\n",
    "- Explorar transformaciones de variables (p. ej. logaritmos)\n",
    "- Utilizar otros modelos de regresión.\n",
    "- Explorar variables no incluidas en el modelo de regresión.\n",
    "- Utilizar bootstrapping para las estimaciones de intervalos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef4d76-7407-46c1-8ce1-58ee45bd9af5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Independencia en los errores\n",
    "Los errores deben ser independientes en una regresión, esto es, no relacionados entre sí.  Generalmente esto implica evaluar la autocorrelación (correlación entre valores adyacentes) y se lleva a cabo mediante la prueba de Durbin-Watson (solamente en series de tiempo). En esta prueba, el estadístico de prueba puede tomar valores entre 0 y 4. Si el estadístico es cercano a 2 entonces los residuales no están correlacionados. Valores menores a 1 o mayores a 3 son señal de un problema serio de autocorrelación. \n",
    "\n",
    "*¿Qué hacer si se detecta autocorrelación en los residuales?*\n",
    "- Explorar modelos específicos para series temporales (ARIMA, SARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf3d4c-a8b9-423a-a3f5-765d8525601b",
   "metadata": {},
   "source": [
    "### Multicolinealidad\n",
    "La multicolinealidad se presenta cuando existe una fuerte correlación entre dos o más variables independientes o una combinación lineal de ellas. La multicolinealidad puede llevar a tener un modelo estadísticamente significativo, pero coeficientes de regresión no significativos.\n",
    "\n",
    "Para evaluar la multicolinealidad:\n",
    "- Revisar la matriz de correlaciones de las variables independientes para identificar correlaciones arriba de 0.90\n",
    "- Revisar el número de condición, valores mayores a 30 indicarían un problema grave\n",
    "- Calcular el Factor de Inflación de Varianza de cada variable, valores mayores a 10 indicarían un problema grave\n",
    "\n",
    "*¿Qué hacer si se detecta multicolinealidad?*\n",
    "- Regularizar (regresión Lasso o Ridge).\n",
    "- Combinar variables.\n",
    "- Eliminar variables redundantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c24a73-beda-4e7e-a925-b9c4a45242b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "X = df[['construccion', 'baños']]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Calcular valores VIF para cada variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Variable'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2c9a0-a9ef-42b2-aee3-b05f399a5ea7",
   "metadata": {},
   "source": [
    "## Extra: uso de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b489dc-b5de-4afc-9a06-49229a17d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la biblioteca\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23965f7a-fe53-453f-9976-26fef1d80a95",
   "metadata": {},
   "source": [
    "Con *SciKit-Learn' no se agrega la columna de constantes como en StatsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbb2df-316e-4cb1-a61a-ee132f86762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['construccion']]\n",
    "y = df['preciomillones']\n",
    "model = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d1a36-568b-4a7c-b8bc-8ae37e76483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los coeficientes de regresión\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee91ab2-166b-48cd-8a33-c58bad126867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener y estimada (y hat)\n",
    "y_hat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93b457-c105-43ee-bf1e-b53597cbea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener residuales\n",
    "residuales = (y - y_hat).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b15581-138d-447d-83ff-77a2ac1431be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular R cuadrada\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49669161-4dbb-4cd8-9683-343e76c164f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
