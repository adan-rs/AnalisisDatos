{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc7a6a8-7b95-42a3-ae4d-1acce323a449",
   "metadata": {},
   "source": [
    "# Preparación de datos\n",
    "*\"Es un error capital teorizar antes de tener datos. Sin darse cuenta, uno empieza a deformar los hechos para que se ajusten a las teorías, en lugar de ajustar las teorías a los hechos.\"  \n",
    "Arthur Conan Doyle en \"Escándalo en Bohemia\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218eb4b-0951-493a-bb40-4349e0324eca",
   "metadata": {},
   "source": [
    "## Selección de filas y columnas\n",
    "\n",
    "Airbnb es una plataforma en línea que permite a los usuarios alquilar alojamientos. El archivo \"listings_cdmx.csv\" contiene el listado de alojamientos en la Ciudad de México, con información básica actualizada al 25 de septiembre de 2024. Las variables disponibles son:\n",
    "- id: identificador del anuncio de alojamiento.\n",
    "- name: nombre del alojamiento.\n",
    "- host_id: identificador del anfitrión.\n",
    "- host_name: nombre del anfitrión\n",
    "- neighbourhood_group:\n",
    "- neighbourhood: alcaldía.\n",
    "- latitude: latitud.\t\n",
    "- longitude: longitud.\n",
    "- room_type: Puede ser \"Entire place\", \"Private room\", \"Shared room\" u \"Hotel\".\n",
    "- price: Precio en moneda nacional ($ MXN).\n",
    "- minimum_nights: mínimo de noches de estadía.\n",
    "- last_review: fecha de la última reseña.\n",
    "- reviews_per_month: promedio de reseñas por mes en el tiempo publicado.\t\n",
    "- calculated_host_listings_count: número de anuncios que tiene el anfitrión.\n",
    "- availability_365: Dias disponibles en los siguientes 365 días.\n",
    "- number_of_reviews_ltm: número de reseñas en los últimos 12 meses.\n",
    "- license: número de licencia o registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a8a4a-ad36-479a-968b-ef3a6b8dcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la biblioteca de pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e918ad6c-1ba1-4ec8-87dd-d25374344864",
   "metadata": {},
   "source": [
    "Para propósitos de este ejercicio solo usaremos algunas de las variables disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9109c73-2b62-4e45-b2b9-5ccc4e131a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga de archivo\n",
    "filepath = '../datasets/listings_cdmx.csv'\n",
    "#filepath = 'https://github.com/adan-rs/AnalisisDatos/raw/main/datasets/listings_cdmx.csv'\n",
    "columns = [\"host_id\", \"neighbourhood\", \"room_type\", \"price\", \n",
    "             \"minimum_nights\", \"number_of_reviews_ltm\", \"license\"]\n",
    "original_data = pd.read_csv(filepath, usecols=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970af86-4d8e-4f81-a807-e47bfcccb45d",
   "metadata": {},
   "source": [
    "Aunque es común utilizar `df` como nombre de un DataFrame, es recomendable utilizar nombres descriptivos que nos permitan distinguir si los datos son originales, seleccionados o procesados.\n",
    "\n",
    "Revisa la información del dataframe con `.head()` y `.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9bbde-c489-4a78-ad90-aa6ac2381bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7616b2-5ad8-4402-831f-051e56766c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76f7a6-e742-4831-82cf-fcc3026de17e",
   "metadata": {},
   "source": [
    "Observa que la variable *host_id* tiene valores numéricos no es una variable cuantitativa. La reclasificaremos como *object* para evitar que se hagan operaciones matemáticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9492e4-af83-4456-981a-6564ae02e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data[\"host_id\"] = original_data[\"host_id\"].astype('object')\n",
    "original_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68520d1-521e-43e4-b5cc-bdc790addfb6",
   "metadata": {},
   "source": [
    "La base de datos abarca diferentes tipos de hospedajes. Mediante `df['A'].value_counts()` podemos consultar qué categorías y frecuencias tiene una variable 'A' en un dataframe llamado 'df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf334d-208b-47a4-8282-bb522aceff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtén la frecuencia por tipo de hospedaje\n",
    "original_data['room_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a29d0c-b29a-4dbb-9fa2-61ab9a0f1b93",
   "metadata": {
    "tags": []
   },
   "source": [
    "Seleccionaremos solamente casos bajo dos condiciones específicas:\n",
    "- Anuncios de casas o departamentos: `original_data['room_type'] == 'Entire home/apt'`\n",
    "- Anuncios con al menos una reseña en el último año: `original_data['number_of_reviews_ltm'] > 0`\n",
    "  \n",
    "Si incluimos dos condiciones en un filtro debemos poner cada condición en un paréntesis:  \n",
    "`mask = (original_data['room_type'] == 'Entire home/apt') & (original_data['number_of_reviews_ltm] > 0)`  \n",
    "Ahora podemos utilizar:   \n",
    "`original_data = original_data[mask]`  \n",
    "o bien  \n",
    "`original_data = original_data.loc[mask]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea9974-aa62-4168-8997-128341178740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar casas o departamentos con reseñas recientes.\n",
    "mask = (original_data['room_type'] == 'Entire home/apt') & (original_data['number_of_reviews_ltm'] > 0)\n",
    "original_data = original_data.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdec2b6-e8da-4c93-a001-ab51fc706649",
   "metadata": {},
   "source": [
    "Una buena práctica es trabajar sobre una copia para no modificar los datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0354dda-933d-474d-8ef9-537615d1ad6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear copia del DataFrame original\n",
    "df = original_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda4b8e-0e55-4554-a4dc-2f984947215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407352fb-391c-484c-a06f-5c4f7d4d3ecf",
   "metadata": {},
   "source": [
    "Todos los pasos anteriores del código se pueden encapsular en una función con un nombre descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70fca65-6fb6-42b4-a390-4bf8ea37dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter(filepath):\n",
    "    \"\"\"\n",
    "    Carga y limpieza de datos originales.\n",
    "    \"\"\"\n",
    "    columns = [\"host_id\", \"neighbourhood\", \"room_type\", \"price\", \n",
    "               \"minimum_nights\", \"number_of_reviews_ltm\", \"license\"]\n",
    "    data = pd.read_csv(filepath, usecols=columns)\n",
    "    data[\"host_id\"] = data[\"host_id\"].astype('object')\n",
    "    mask = (data['room_type'] == 'Entire home/apt') & (data['number_of_reviews_ltm'] > 0)\n",
    "    return data.loc[mask].copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea2388-e67d-45f9-ae8b-7a2c02062e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/listings_cdmx.csv'\n",
    "df = load_and_filter(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121b10a-7c83-4249-bfe7-8b87bd3bb70c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datos duplicados\n",
    "En algunas ocasiones puede haber datos duplicados en nuestra base de datos. Para visualizar los datos duplicados podemos usar *duplicated()* de la siguiente manera:\n",
    "`df[df.duplicated()]`. Si nos interesa en la variable \"A\" en particular entonces es `df[df['A'].duplicated()]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228a140-5d4b-4a63-8b23-2a37b446f208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica los datos duplicados en todas las variables \n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e92d6-d878-41e0-b8dd-4920f6c1be90",
   "metadata": {},
   "source": [
    "Una opción para eliminar datos duplicados es usar *drop_duplicates()*. En nuestro ejemplo sería: `df.drop_duplicates()`. Esto sólo elimina observaciones filas duplicadas en todas las variables. De manera predeterminada, solamente conserva la primera fila de ellas.  \n",
    "En algunas ocasiones necesitaremos eliminar observaciones duplicadas en solamente algunas variables. En ese caso se puede agregar un listado con el argumento *subset*, por ejemplo: `df = df.drop_duplicates(subset=['hotel_id'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ffe79-46a1-4f02-b735-20517e965afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Elimina filas duplicadas en todas las columnas y registra la cantidad \n",
    "    de filas eliminadas.Retorna DataFrame sin valores duplicados.\n",
    "    \"\"\"\n",
    "    rows_before = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    rows_after = len(df)\n",
    "    print(f\"Se eliminaron {rows_before - rows_after} filas duplicadas\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027720a8-b877-418b-bdae-857119dcb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23ad92-68c6-452a-a868-418cf8fbb0e2",
   "metadata": {},
   "source": [
    "## Datos perdidos\n",
    "En el caso de datos perdidos es importante determinar si se pueden considerar aleatorios o si existe un patrón que pueda afectar los resultados. En una encuesta, por ejemplo, es posible que las personas que prefieran no mencionar su ingreso tengan ciertas características, o bien, que las personas tiendan a no responder a preguntas sobre cierto tipo de comportamiento que no es socialmente aceptable.\n",
    "\n",
    "Es recomendable realizar pruebas estadísticas para verificar si los datos perdidos pueden ser considerados aleatorios o no. Bajo el procedimiento habitual, se construyen dos grupos, uno de observaciones con datos completos y otro grupo de observaciones con datos perdidos en una variable en particular. Posteriormente, se realizan pruebas para comparar si existen diferencias significativas en los valores promedio de las otras variables\n",
    "\n",
    "Como una aproximación inicial, el método `info()` puede servir para identificar qué variables tienen valores perdidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c7073-a004-496d-8f5a-be7d878acb2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica qué variables tienen valores perdidos con 'info()'\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227aa539-568d-49ab-bade-3a540aad237d",
   "metadata": {},
   "source": [
    "Para encontrar las filas con datos perdidos podemos usar `df[df.isna().any(axis=1)]`. El método *isna()* sirve para indicar qué valores son perdidos y el método *any* sirve para indicar qué filas tienen al menos un valor perdido. Otra opción equivalente a `isna()` es `isnull()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df3e86-22a0-43c0-a84e-ff58d097443e",
   "metadata": {},
   "source": [
    "Para encontrar las filas con datos perdidos de una variable en particular (por ejemplo \"price\") podemos usar `df[df.price.isna()]`. El método isna() sirve para indicar qué valores son perdidos. Para encontrar todas las filas con datos perdidos podemos usar `df[df.isna().any(axis=1)]` donde el método any sirve para indicar qué filas tienen al menos un valor perdido. Otra opción equivalente a isna() es isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc5d90-bb13-42d6-8183-f25619c3eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar filas con datos perdidos en una variable\n",
    "df[df.price.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085062f-edda-4284-8de7-1e80293166ce",
   "metadata": {},
   "source": [
    "*¿Qué hacer con datos perdidos?*  \n",
    "Los métodos más comunes para tratar con datos perdidos son:\n",
    "- Borrar filas o columnas con datos perdidos. Si una columna tiene una gran cantidad de datos perdidos, considera excluir esa columna del análisis. Si pocas filas tienen datos perdidos (digamos, menos del 5%) y estos parecen ser completamente aleatorios, borrar las filas correspondientes es una alternativa. Sin embargo, en series de tiempo no es recomendable eliminar filas (*¿por qué?*)\n",
    "- Codificar: Los datos perdidos también pueden aportar información en un análisis, por lo que en variables no numéricas se puede codificar los datos perdidos en una categoría adicional.\n",
    "- Imputación simple: Reemplazar los datos perdidos con un valor calculado a partir de la misma variable. La opción más común y conservadora es utilizar el promedio. Sin embargo, este método es criticado debido a que reduce la variabilidad y afecta la estimación de los intervalos de confianza (Treiman, 2009).\n",
    "- Imputación multivariada: Reemplazar los datos perdidos con un valor calculado a partir de otras variables. En la imputación de datos por medio de la regresión se utilizan otras variables en la base de datos para establecer una ecuación de regresión en la que la variable dependiente es la variable con los datos perdidos. La ecuación de regresión estimada se utiliza para estimar los datos perdidos \n",
    "\n",
    "\n",
    "En cuanto a otros métodos de estimación se recomienda la lectura del capítulo “Multiple imputation of missing data” de Treiman (2009).\n",
    "\n",
    "\n",
    "*Imputación simple o univariada*  \n",
    "La imputación con la media para una columna 'A' es:  \n",
    "`df['A'] = df['A'].fillna(df['A'].mean())`  \n",
    "En caso de querer la imputación con la mediana se reemplaza `mean()` con `median()` y en el caso de la moda se reemplaza con `mode().iloc[0]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214cd65-7549-45f7-a9b6-4d29d933034d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_data(df, threshold=0.2):\n",
    "    \"\"\" \n",
    "    Maneja datos perdidos según el tipo de datos de cada columna, \n",
    "    y elimina columnas con un porcentaje de datos perdidos mayor a \n",
    "    un umbral específico. \n",
    "    Retorna DataFrame procesado sin valores nulos.\n",
    "    \"\"\"  \n",
    "    print(\"\\nValores faltantes por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Remove columns with high proportion of missing values\n",
    "    cols_with_nulls = df.isnull().mean() > threshold\n",
    "    cols_to_drop = df.columns[cols_with_nulls]\n",
    "    if len(cols_to_drop) > 0:\n",
    "        print(f\"\\nColumnas eliminadas por tener más de {threshold*100}% de valores nulos:\")\n",
    "        print(cols_to_drop.tolist())\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Handle missing values in remaining columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        elif df[col].dtype == 'string':\n",
    "            df[col] = df[col].fillna('DESCONOCIDO')\n",
    "            \n",
    "    total_remaining_nulls = df.isna().sum().sum()\n",
    "    print(f\"\\nValores nulos restantes: {total_remaining_nulls}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67add1f2-ea70-41d4-8e98-c34c6f0deb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_missing_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febcc66-3fb4-404d-afa3-ac0826c58a31",
   "metadata": {},
   "source": [
    "## Valores atípicos\n",
    "Un valor atípico (outlier) es un valor extremo en una o más variables. En el caso de series univariadas, es común utilizar el método del valor z o el criterio del rango intercuartil para identificar valores atípicos. Para el caso de datos multivariados generalmente se utilizan criterios basados en la distancia de Mahalanobis y otras técnicas multivariadas. \n",
    "\n",
    "*¿Qué hacer con datos atípicos?*\n",
    "- Si el valor extremo es un error de captura o parte de otra población lo recomendable es corregir o borrar el caso o variable.\n",
    "- Si el valor extremo es parte de los datos que nos interesa analizar se debe mantener (p. ej. ventas en navidad).\n",
    "- En algunas variables económicas se recomienda transformar la variable de forma tal que el valor extremo no impacte los resultados (p. ej. transformación logarítmica, transformación de Box-Cox o la recodificación de datos).\n",
    "\n",
    "\n",
    "*Método del valor z*: En este enfoque un valor atípico es aquel que esté a más de tres desviaciones estándar a partir de la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d1042-ecea-49a2-a98c-21de5b1ab0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_outliers_3s(df, column):\n",
    "    \"\"\"\n",
    "    Elimina valores atípicos utilizando el método del valor z. \n",
    "    Retorna un DataFrame sin valores atípicos.\n",
    "    \"\"\"\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    upper_limit = mean + 3 * std\n",
    "    lower_limit = mean - 3 * std\n",
    "    df_clean = df[(df[column] > lower_limit) & (df[column] < upper_limit)]\n",
    "    excluded_values = len(df) - len(df_clean)\n",
    "    print(f\"Cantidad de valores atípicos excluidos: {excluded_values}\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b971c0-8f65-4076-9dff-b62ee2056d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers_3s(df,'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb30c45-72a1-4144-b998-22f0eb4fc829",
   "metadata": {},
   "source": [
    "*Método del rango intercuartil*. Otro criterio común es considerar como atípicos los valores que están a más de 1.5 veces el rango intercuartil hacia el extremo a partir del 1er. o 3er. cuartil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6704f-a6e5-4373-a4e0-3f00a750887f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, column):\n",
    "    \"\"\"\n",
    "    Elimina valores atípicos utilizando el criterio del rango intercuartil.\n",
    "    Retorna DataFrame sin valores atípicos.\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    df_clean = df[(df[column] > lower_limit) & (df[column] < upper_limit)]\n",
    "    excluded_values = len(df) - len(df_clean)\n",
    "    print(f\"Cantidad de valores atípicos excluidos: {excluded_values}\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db7f53-c21d-40ff-a620-1a239f1fb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers_iqr(df, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7797bc-2120-4d13-9dfa-4c8194ec6ac4",
   "metadata": {},
   "source": [
    "*Algoritmo isolation forest*: Es un algoritmo utilizado para detectar valores atípicos en grandes conjuntos de datos. Divide los datos de manera aleatoria y cuanto más rápido se aísla un punto mayor es la probabilidad de que sea un valor atípico (anomalía)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86646141-a595-45e6-94ba-e6ec103113a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def remove_outliers_iso_forest(df, columns, contamination=0.05, random_state=42):\n",
    "    \"\"\"\n",
    "    Elimina valores atípicos utilizando el algoritmo Isolation Forest.\n",
    "    Retorna DataFrame sin valores atípicos.\n",
    "    \"\"\"\n",
    "    # Initialize and fit Isolation Forest model\n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "    iso_forest.fit(df[columns])\n",
    "    \n",
    "    # Predict labels: 1 (normal) or -1 (outlier)\n",
    "    labels = iso_forest.predict(df[columns])\n",
    "    \n",
    "    # Calculate and display number of excluded outliers\n",
    "    df_clean = df[labels == 1]\n",
    "    excluded_values = len(df) - len(df_clean)\n",
    "    print(f\"\\nCantidad de valores atípicos excluidos: {excluded_values}\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39bb791-2af9-4dec-add2-e08c350e9b21",
   "metadata": {},
   "source": [
    "Seleccionaremos este último criterio para filtrar datos atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fabbaf-3c20-425b-82d0-139f34ae6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers_iso_forest(df, columns=['price', 'minimum_nights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c25e31-dce3-453c-a83c-6cdf25801722",
   "metadata": {},
   "source": [
    "## Reporte general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a3c83-6efd-476d-9c3b-bcde547b2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quality_report(df):\n",
    "    \"\"\"\n",
    "    Genera un reporte básico de calidad de datos que incluye\n",
    "        - Dimensiones del DataFrame\n",
    "        - Tipos de datos por columna\n",
    "        - Cantidad de valores únicos por columna\n",
    "        - Estadísticas descriptivas para columnas numéricas\n",
    "    \"\"\"\n",
    "    print(\"\\nREPORTE DE CALIDAD DE DATOS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"Dimensiones del DataFrame: {df.shape}\")\n",
    "    print(f\"\\nTipos de datos:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Unique values per column\n",
    "    print(\"\\nValores únicos por columna:\")\n",
    "    for column in df.columns:\n",
    "        unique_count = df[column].nunique()\n",
    "        print(f\"{column}: {unique_count} valores únicos\")\n",
    "    \n",
    "    # Basic statistics for numeric columns\n",
    "    print(\"\\nEstadísticas básicas:\")\n",
    "    print(df.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc1bc1-a659-47b6-99b1-ff8dd0dd341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reporte de calidad de datos\n",
    "generate_quality_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb6cac-b8a4-43f7-b922-4c1661a836cc",
   "metadata": {},
   "source": [
    "## Exportar datos (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff54bb-1ce6-46dc-9b3f-a8f8f959c05c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Un dataframe lo podemos guardar con `df.to_excel('archivo.xlsx', index=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105dc65f-650c-4c21-af8d-388e4f1c96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta el dataframe depurado con el nombre 'output'\n",
    "# df.to_excel('output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae45e6-83ac-41d9-955a-7bb55f3e26e7",
   "metadata": {},
   "source": [
    "## Resumen del flujo de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9673b6-a08b-4b4b-bf29-5b959ecfbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo de origen\n",
    "filepath = '../datasets/listings_cdmx.csv'\n",
    "\n",
    "# Selección de datos\n",
    "df = load_and_filter(filepath)\n",
    "    \n",
    "# Eliminar filas duplicadas\n",
    "df = remove_duplicates(df)\n",
    "    \n",
    "# Manejar datos perdidos\n",
    "df = handle_missing_data(df)\n",
    "\n",
    "# Eliminar valores atípicos\n",
    "df = remove_outliers_iso_forest(df, columns=['price', 'minimum_nights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2c442-b5a1-4ea5-bbb4-27b5355db2fc",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "En un nuevo notebook, utiliza las funciones creadas y el flujo de trabajo para procesar los datos de Airbnb en otra ciudad. Por ejemplo, reemplaza el filepath por `'../datasets/listings_madrid.csv'` o el enlace al archivo original:  \n",
    "`'https://data.insideairbnb.com/spain/comunidad-de-madrid/madrid/2024-09-11/visualisations/listings.csv'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2bf36-d30f-4cb6-a9dc-967d97886a99",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- Una discusión interesante sobre el tratamiento de datos se puede encontrar en: Treiman, D. J. (2009). *Quantitative data analysis. Doing social research to test ideas*. San Francisco, CA: Jossey-Bass.\n",
    "- La base de datos fue tomada de https://insideairbnb.com/get-the-data/ para fines no comerciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccd2cdf-c721-483c-8efb-22bc9b79295f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
