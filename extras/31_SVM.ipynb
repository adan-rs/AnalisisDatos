{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb7e824-5bd7-487e-b3f7-f4e331230b1b",
   "metadata": {},
   "source": [
    "# Máquinas de soporte vectorial (SVM)\n",
    "\n",
    "*¿Para qué se utiliza?*\n",
    "Las Máquinas de Soporte Vectorial (SVM) son modelos de machine learning supervisado utilizados principalmente para clasificación y también para regresión (con variantes como SVR). Su objetivo es encontrar el hiperplano óptimo que separa las clases con el mayor margen posible. Las SVM son especialmente útiles cuando los datos no son linealmente separables, ya que permiten el uso de funciones kernel para proyectar los datos en espacios de mayor dimensión donde sí pueden separarse.\n",
    "\n",
    "*¿Qué variables considera?*\n",
    "Variable dependiente:\n",
    "- En clasificación: variable categórica (2 clases o multiclase).\n",
    "- En regresión: variable continua.\n",
    "Variables independientes:\n",
    "- Pueden ser numéricas o transformadas en numéricas (por ejemplo, mediante codificación one-hot para datos categóricos).\n",
    "- El modelo aprende los vectores de soporte, que son los puntos clave cercanos a los límites de separación.\n",
    "\n",
    "*¿Cómo funciona?*\n",
    "SVM busca un hiperplano (una línea en 2D, un plano en 3D, etc.) que separe las clases con el máximo margen. Este margen es la distancia entre el hiperplano y los vectores más cercanos de cada clase. Si los datos no son linealmente separables, SVM usa kernels como lineal, polinomial o RBF (radial basis function, muy común). Estos permiten transformar los datos a espacios donde puedan separarse de forma más efectiva.\n",
    "\n",
    "*Supuestos y recomendaciones*\n",
    "- No requiere supuestos de normalidad ni homocedasticidad.\n",
    "- Requiere que las variables estén escaladas para obtener buenos resultados.\n",
    "- Es muy eficaz en espacios de alta dimensión y cuando hay una clara separación entre clases.\n",
    "- Puede ser sensible al ruido o valores atípicos.\n",
    "- Para datos grandes, puede ser computacionalmente costos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1820fef-6602-464e-8d38-3a91a95109f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suponemos que df tiene variables predictoras y una variable objetivo 'y'\n",
    "X = df.drop(columns='y')\n",
    "y = df['y']\n",
    "\n",
    "# Escalar los datos (importante para SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# División en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo SVM\n",
    "modelo = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = modelo.predict(X_test)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "ConfusionMatrixDisplay.from_estimator(modelo, X_test, y_test, cmap='Blues')\n",
    "plt.title(\"Matriz de Confusión - SVM\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
