{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc7a6a8-7b95-42a3-ae4d-1acce323a449",
   "metadata": {},
   "source": [
    "# Preparación de datos\n",
    "*\"Es un error capital teorizar antes de tener datos. Sin darse cuenta, uno empieza a deformar los hechos para que se ajusten a las teorías, en lugar de ajustar las teorías a los hechos.\"  \n",
    "Arthur Conan Doyle en \"Escándalo en Bohemia\".*\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En el análisis de datos, la calidad de los resultados depende directamente de la calidad de los datos con los que trabajamos. Antes de realizar análisis avanzados, es necesario realizar un proceso que usualmente incluye:  \n",
    "1. *Revisión inicial de los datos*: revisión de la estructura de los datos, detección de inconsistencias y errores, y selección de filas y columnas.\n",
    "2. *Limpieza de datos*: corrección de errores, manejo de datos duplicados, tratamiento de datos perdidos, identificación y tratamiento de valores atípicos\n",
    "3. *Transformación de datos*: creación de nuevas variables, consolidar variables, recodificación de variables, transformación a valores estandarizados.\n",
    "4. *Validación de datos*: verificación de la calidad de los datos, documentación de cada paso aplicado y pruebas de supuestos estadísticos.\n",
    "\n",
    "Específicamente en esta práctica, revisaremos diferentes técnicas para identificar y manejar datos duplicados, datos perdidos y valores atípicos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218eb4b-0951-493a-bb40-4349e0324eca",
   "metadata": {},
   "source": [
    "**Datos**: Airbnb es una plataforma en línea que permite a los usuarios alquilar alojamientos. El archivo \"listings_cdmx.csv\" contiene el listado de alojamientos en la Ciudad de México, con información básica actualizada al 25 de septiembre de 2024. Las variables disponibles son:\n",
    "- id: identificador del anuncio de alojamiento.\n",
    "- name: nombre del alojamiento.\n",
    "- host_id: identificador del anfitrión.\n",
    "- host_name: nombre del anfitrión\n",
    "- neighbourhood_group:\n",
    "- neighbourhood: alcaldía.\n",
    "- latitude: latitud.\t\n",
    "- longitude: longitud.\n",
    "- room_type: Puede ser \"Entire place\", \"Private room\", \"Shared room\" u \"Hotel\".\n",
    "- price: Precio en moneda nacional ($ MXN).\n",
    "- minimum_nights: mínimo de noches de estadía.\n",
    "- last_review: fecha de la última reseña.\n",
    "- reviews_per_month: promedio de reseñas por mes en el tiempo publicado.\t\n",
    "- calculated_host_listings_count: número de anuncios que tiene el anfitrión.\n",
    "- availability_365: Dias disponibles en los siguientes 365 días.\n",
    "- number_of_reviews_ltm: número de reseñas en los últimos 12 meses.\n",
    "- license: número de licencia o registro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a8a4a-ad36-479a-968b-ef3a6b8dcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la biblioteca de pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954fbe1-6576-4a89-bd6e-1b81ec3efd02",
   "metadata": {},
   "source": [
    "**Selección de columnas**: Para cargar un subconjunto de columnas específicas desde un archivo, utiliza el parámetro `usecols` de las funciones `pd.read_csv()` o `pd.read_excel()`. Esto permite crear un listado para preseleccionar las variables con las que deseas trabajar y optimizar el espacio en memoria que ocupa el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8170a-4ae7-49f7-9edc-80421a256965",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"host_id\", \"neighbourhood\", \"room_type\", \"price\", \n",
    "             \"minimum_nights\", \"number_of_reviews_ltm\", \"license\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de0c0f-b51e-43dc-bd8d-16503882f982",
   "metadata": {},
   "source": [
    "**Uso de nombres descriptivos**: Aunque es común usar `df` como nombre de un DataFrame, es recomendable emplear nombres descriptivos que indiquen si los datos son originales (*df_original, raw_data, input_data, source_df*, etc.), seleccionados o procesados. Esto facilitará la comprensión del código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9109c73-2b62-4e45-b2b9-5ccc4e131a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga de archivo\n",
    "#filepath = '../datasets/listings_cdmx.csv'\n",
    "url = 'https://github.com/adan-rs/AnalisisDatos/raw/main/data/listings_cdmx.csv'\n",
    "df_original = pd.read_csv(url, usecols=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970af86-4d8e-4f81-a807-e47bfcccb45d",
   "metadata": {},
   "source": [
    "**Revisión de la estructura de los datos**: Revisa la información del DataFrame con los siguientes comandos:\n",
    "- `df.columns`: muestra los nombres de las columnas \n",
    "- `df.shape`: muestra el número de filas y columnas.\n",
    "- `df.info()`: proporciona un resumen de las columnas, incluyendo sus tipos de datos y valores nulos.\n",
    "- `df.head()`: muestra las primeras filas del DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9bbde-c489-4a78-ad90-aa6ac2381bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7616b2-5ad8-4402-831f-051e56766c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76f7a6-e742-4831-82cf-fcc3026de17e",
   "metadata": {},
   "source": [
    "**Detección de inconsistencias en tipos de variables**: Observa que no todas las variables numéricas son cuantitativas. Por ejemplo, si la columna host_id contiene valores numéricos pero no representa una variable cuantitativa, reclasifícala para evitar operaciones matemáticas inapropiadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9492e4-af83-4456-981a-6564ae02e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[\"host_id\"] = df_original[\"host_id\"].astype('object')\n",
    "df_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68520d1-521e-43e4-b5cc-bdc790addfb6",
   "metadata": {},
   "source": [
    "**Estadística descriptiva: tablas de frecuencia (opcional)**: Si deseas conocer las categorías y frecuencias de una variable categórica, utiliza `df['A'].value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf334d-208b-47a4-8282-bb522aceff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la distribución de frecuencias\n",
    "df_original['room_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a29d0c-b29a-4dbb-9fa2-61ab9a0f1b93",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Selección de filas**: Para seleccionar datos bajo condiciones específicas, usa expresiones lógicas. Por ejemplo, para filtrar:\n",
    "- Anuncios de casas o departamentos:  \n",
    "  `df_original['room_type'] == 'Entire home/apt'`\n",
    "- Anuncios con al menos una reseña en el último año:  \n",
    "  `df_original['number_of_reviews_ltm'] > 0`\n",
    "\n",
    "Combina ambas condiciones en un filtro colocando cada condición dentro de un paréntesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5a2a9-7b34-4fd9-b0fc-1083a00b0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_original['room_type'] == 'Entire home/apt') & (df_original['number_of_reviews_ltm'] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d8336-10ad-4b9e-9611-0fb0e671ab27",
   "metadata": {},
   "source": [
    "Luego aplica el filtro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b464a1-8f6d-40ae-b74d-aae464e707d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado = df_original[mask]\n",
    "# o bien\n",
    "df_filtrado = df_original.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91295a88-9c43-4bab-98ed-70831a9de60d",
   "metadata": {},
   "source": [
    "**Estadística descriptiva: medidas numéricas (opcional)**: Si deseas obtener las principales medidas numéricas de las variables cualitativas utiliza `df.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9c655-6be8-4f00-87db-c1f67c4d6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener medidas numéricas:\n",
    "df_original.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdec2b6-e8da-4c93-a001-ab51fc706649",
   "metadata": {},
   "source": [
    "**Evitar modificaciones no intencionales**: Es una buena práctica trabajar sobre una copia de los datos originales para preservar su integridad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0354dda-933d-474d-8ef9-537615d1ad6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear copia del DataFrame original\n",
    "df = df_filtrado.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407352fb-391c-484c-a06f-5c4f7d4d3ecf",
   "metadata": {},
   "source": [
    "**Encapsulación del proceso (opcional)**: Para mantener un código limpio y reutilizable, encapsula los pasos anteriores en una función con un nombre descriptivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70fca65-6fb6-42b4-a390-4bf8ea37dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_filter(filepath):\n",
    "    \"\"\"\n",
    "    Carga y limpieza de datos originales.\n",
    "    \"\"\"\n",
    "    columns = [\"host_id\", \"neighbourhood\", \"room_type\", \"price\", \n",
    "               \"minimum_nights\", \"number_of_reviews_ltm\", \"license\"]\n",
    "    data = pd.read_csv(filepath, usecols=columns)\n",
    "    data[\"host_id\"] = data[\"host_id\"].astype('object')\n",
    "    mask = (data['room_type'] == 'Entire home/apt') & (data['number_of_reviews_ltm'] > 0)\n",
    "    return data.loc[mask].copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea2388-e67d-45f9-ae8b-7a2c02062e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ur = 'https://github.com/adan-rs/AnalisisDatos/raw/main/datasets/listings_cdmx.csv'\n",
    "df = load_and_filter(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121b10a-7c83-4249-bfe7-8b87bd3bb70c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datos duplicados\n",
    "**Identificar datos duplicados**: En ocasiones, nuestra base de datos puede contener información duplicada. Para identificar estos datos duplicados, podemos utilizar el método duplicated() de las siguientes maneras:\n",
    "- Para visualizar todas las filas duplicadas:  \n",
    "  `df[df.duplicated()]`\n",
    "- Si nos interesa analizar duplicados en una columna específica (por ejemplo, \"A\"):  \n",
    "  `df[df['A'].duplicated()]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228a140-5d4b-4a63-8b23-2a37b446f208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica los datos duplicados en todas las variables \n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e92d6-d878-41e0-b8dd-4920f6c1be90",
   "metadata": {},
   "source": [
    "**Eliminar datos duplicados**: Para eliminar datos duplicados, se utiliza el método `drop_duplicates()` que conserva la primera ocurrencia de cada duplicado. En el ejemplo general, podemos eliminar filas duplicadas (considerando todas las variables) mediante:  \n",
    "`df = df.drop_duplicates()`  \n",
    "Si necesitamos eliminar duplicados considerando sólo algunas variables, podemos usar el parámetro subset:  \n",
    "`df = df.drop_duplicates(subset=['hotel_id'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ffe79-46a1-4f02-b735-20517e965afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Elimina filas duplicadas en todas las columnas y registra la cantidad \n",
    "    de filas eliminadas.Retorna DataFrame sin valores duplicados.\n",
    "    \"\"\"\n",
    "    rows_before = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    rows_after = len(df)\n",
    "    print(f\"Se eliminaron {rows_before - rows_after} filas duplicadas\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79122120-f8cc-4c84-90b1-ee818ad7995d",
   "metadata": {},
   "source": [
    "Observa que en la línea de `print()` aparece `f\"` que se utiliza para indicar un formato llamado *f-strings* que permite insertar valores o expresiones dentro de llaves {} en una cadena de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027720a8-b877-418b-bdae-857119dcb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23ad92-68c6-452a-a868-418cf8fbb0e2",
   "metadata": {},
   "source": [
    "## Datos perdidos\n",
    "Los datos perdidos pueden influir significativamente en los resultados del análisis, por lo que es importante determinar si estos son aleatorios o si siguen algún patrón específico. Por ejemplo, en una encuesta, es posible que quienes omitan informar su ingreso compartan ciertas características o que preguntas sobre comportamientos socialmente indeseables tengan tasas de no respuesta más altas.\n",
    "\n",
    "Para determinar si los datos perdidos son aleatorios, es común realizar pruebas estadísticas. El procedimiento general incluye:\n",
    "- Dividir las observaciones en dos grupos:\n",
    "    - Grupo con datos completos.\n",
    "    - Grupo con valores perdidos en una variable específica.\n",
    "- Comparar los valores promedio de otras variables entre ambos grupos mediante pruebas de significancia.\n",
    "\n",
    "Estas pruebas permiten identificar si los datos perdidos podrían estar relacionados con alguna característica específica de los datos.\n",
    "\n",
    "**Análisis inicial de datos perdidos**: Una herramienta útil para identificar variables con valores perdidos es el método `info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c7073-a004-496d-8f5a-be7d878acb2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica qué variables tienen valores perdidos con 'info()'\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587b488-94c7-494a-a270-fcd302d6ab01",
   "metadata": {},
   "source": [
    "Para identificar filas con al menos un valor perdido, podemos usar `df[df.isna().any(axis=1)]`\n",
    "donde`isna()` identifica los valores perdidos y `any(axis=1)` verifica si existe al menos un valor perdido en cada fila."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df3e86-22a0-43c0-a84e-ff58d097443e",
   "metadata": {},
   "source": [
    "Para encontrar las filas con datos perdidos de una variable en particular (por ejemplo \"price\") podemos usar `df[df.price.isna()]`. Otra opción equivalente a `isna()` es `isnull()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc5d90-bb13-42d6-8183-f25619c3eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar filas con datos perdidos en una variable\n",
    "df[df.price.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085062f-edda-4284-8de7-1e80293166ce",
   "metadata": {},
   "source": [
    "**¿Qué hacer con datos perdidos?**  \n",
    "Existen diversas estrategias para tratar los datos faltantes, dependiendo del contexto y las características del problema. A continuación, se presentan las más comunes:\n",
    "\n",
    "1. *Eliminar filas o columnas con datos faltantes*: Si una columna no es esencial y tiene una gran cantidad de datos faltantes (por ejemplo, más del 20%), puede ser razonable excluirla del análisis. Si solo unas pocas filas contienen datos faltantes (por ejemplo, menos del 5%) y estas ausencias parecen ser completamente aleatorias, eliminarlas puede ser una solución viable. Sin embargo, en el caso de series de tiempo, eliminar filas puede distorsionar los patrones temporales y no es una práctica recomendada (¿por qué crees que esto ocurre?).\n",
    "\n",
    "2. *Codificación*: Los valores faltantes también pueden contener información valiosa. En variables categóricas, se pueden codificar como una categoría adicional para incluirlos en el análisis.\n",
    "\n",
    "3. *Imputación simple*: Consiste en reemplazar los valores faltantes con un estimado calculado a partir de la misma variable. Una opción común y conservadora es usar el promedio o la mediana. Sin embargo, este método tiene limitaciones, ya que reduce la variabilidad y puede sesgar los intervalos de confianza (Treiman, 2009).\n",
    "\n",
    "4. *Imputación multivariada*: Este enfoque utiliza otras variables del conjunto de datos para estimar los valores faltantes. Por ejemplo, en la imputación basada en regresión, se construye una ecuación de regresión donde la variable dependiente es aquella con datos faltantes. Luego, los valores se predicen utilizando la ecuación estimada.\n",
    "\n",
    "Para profundizar en otros métodos de imputación, se recomienda la lectura del capítulo “Multiple Imputation of Missing Data” de Treiman (2009).\n",
    "\n",
    "*Imputación simple o univariada*  \n",
    "La imputación con la media para una columna 'A' se obtiene con:   \n",
    "`df['A'] = df['A'].fillna(df['A'].mean())`  \n",
    "En caso de querer la imputación con la mediana se reemplaza `mean()` con `median()` y en el caso de la moda se reemplaza con `mode().iloc[0]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214cd65-7549-45f7-a9b6-4d29d933034d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_data(df, threshold=0.2):\n",
    "    \"\"\" \n",
    "    Maneja datos perdidos según el tipo de datos de cada columna, \n",
    "    y elimina columnas con un porcentaje de datos perdidos mayor a \n",
    "    un umbral específico. \n",
    "    Retorna DataFrame procesado sin valores nulos.\n",
    "    \"\"\"  \n",
    "    print(\"\\nValores faltantes por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Remove columns with high proportion of missing values\n",
    "    cols_with_nulls = df.isnull().mean() > threshold\n",
    "    cols_to_drop = df.columns[cols_with_nulls]\n",
    "    if len(cols_to_drop) > 0:\n",
    "        print(f\"\\nColumnas eliminadas por tener más de {threshold*100}% de valores nulos:\")\n",
    "        print(cols_to_drop.tolist())\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Handle missing values in remaining columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64']:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        elif df[col].dtype == 'string':\n",
    "            df[col] = df[col].fillna('DESCONOCIDO')\n",
    "            \n",
    "    total_remaining_nulls = df.isna().sum().sum()\n",
    "    print(f\"\\nValores nulos restantes: {total_remaining_nulls}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2179032-ccb5-4a59-bf11-3d1371e9b2ba",
   "metadata": {},
   "source": [
    "En el código anterior aparece un *iterador* `for..in` que se usa para recorrer de manera secuencial los elementos de una colección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67add1f2-ea70-41d4-8e98-c34c6f0deb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_missing_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7926b48-ed9d-484e-b007-6e17805ac3b0",
   "metadata": {},
   "source": [
    "**Nota**: Estas funciones están diseñadas para datos de corte transversal (cross-sectional) y no deben aplicarse directamente a series de tiempo. En series de tiempo hay que considerar los patrones que tenga la serie para hacer la estimación o interpolación apropiada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febcc66-3fb4-404d-afa3-ac0826c58a31",
   "metadata": {},
   "source": [
    "## Valores atípicos\n",
    "Un valor atípico (outlier) es un dato extremo en una o más variables que se desvía significativamente del resto de las observaciones. \n",
    "\n",
    "**Identificación de datos atípicos**  \n",
    "- En el caso de series univariadas, es común utilizar el método del valor z o el criterio del rango intercuartil para identificar valores atípicos.\n",
    "- Para el caso de datos multivariados se utilizan técnicas estadísticas avanzadas o algoritmos como *isolation forest*.\n",
    "\n",
    "**¿Qué hacer con datos atípicos?**\n",
    "- Si el valor extremo es un error de captura o parte de otra población lo recomendable es corregir o borrar el caso o variable.\n",
    "- Si el valor extremo es parte de los datos que nos interesa analizar se debe mantener (p. ej. ventas en navidad).\n",
    "- En algunas variables económicas se recomienda transformar la variable de forma tal que el valor extremo no impacte los resultados (p. ej. transformación logarítmica, transformación de Box-Cox o la recodificación de datos).\n",
    "\n",
    "\n",
    "*Método del valor z*: En este enfoque un valor atípico es aquel que esté a más de tres desviaciones estándar a partir de la media. Es un enfoque sencillo y ampliamente utilizado en series univariadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d1042-ecea-49a2-a98c-21de5b1ab0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_outliers_3s(df, column):\n",
    "    \"\"\"\n",
    "    Elimina valores atípicos utilizando el método del valor z. \n",
    "    Retorna un DataFrame sin valores atípicos.\n",
    "    \"\"\"\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    upper_limit = mean + 3 * std\n",
    "    lower_limit = mean - 3 * std\n",
    "    df_clean = df[(df[column] > lower_limit) & (df[column] < upper_limit)]\n",
    "    excluded_values = len(df) - len(df_clean)\n",
    "    print(f\"Cantidad de valores atípicos excluidos: {excluded_values}\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b971c0-8f65-4076-9dff-b62ee2056d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers_3s(df,'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb30c45-72a1-4144-b998-22f0eb4fc829",
   "metadata": {},
   "source": [
    "*Método del rango intercuartil*. Otro criterio común es considerar como atípicos los valores que están a más de 1.5 veces el rango intercuartil hacia el extremo a partir del 1er. o 3er. cuartil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6704f-a6e5-4373-a4e0-3f00a750887f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, column):\n",
    "    \"\"\"\n",
    "    Elimina valores atípicos utilizando el criterio del rango intercuartil.\n",
    "    Retorna DataFrame sin valores atípicos.\n",
    "    \"\"\"\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    df_clean = df[(df[column] > lower_limit) & (df[column] < upper_limit)]\n",
    "    excluded_values = len(df) - len(df_clean)\n",
    "    print(f\"Cantidad de valores atípicos excluidos: {excluded_values}\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db7f53-c21d-40ff-a620-1a239f1fb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers_iqr(df, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7797bc-2120-4d13-9dfa-4c8194ec6ac4",
   "metadata": {},
   "source": [
    "*Algoritmo isolation forest*: Es un algoritmo utilizado para detectar valores atípicos en grandes conjuntos de datos. Divide los datos de manera aleatoria y cuanto más rápido se aísla un punto mayor es la probabilidad de que sea un valor atípico (anomalía)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86646141-a595-45e6-94ba-e6ec103113a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def remove_outliers_iso_forest(df, columns, contamination=0.05, random_state=42):\n",
    "    \"\"\"\n",
    "    Elimina valores atípicos utilizando el algoritmo Isolation Forest.\n",
    "    Retorna DataFrame sin valores atípicos.\n",
    "    \"\"\"\n",
    "    # Initialize and fit Isolation Forest model\n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "    iso_forest.fit(df[columns])\n",
    "    \n",
    "    # Predict labels: 1 (normal) or -1 (outlier)\n",
    "    labels = iso_forest.predict(df[columns])\n",
    "    \n",
    "    # Calculate and display number of excluded outliers\n",
    "    df_clean = df[labels == 1]\n",
    "    excluded_values = len(df) - len(df_clean)\n",
    "    print(f\"\\nCantidad de valores atípicos excluidos: {excluded_values}\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39bb791-2af9-4dec-add2-e08c350e9b21",
   "metadata": {},
   "source": [
    "Seleccionaremos este último criterio para filtrar datos atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fabbaf-3c20-425b-82d0-139f34ae6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers_iso_forest(df, columns=['price', 'minimum_nights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc62031-4f8b-4fc6-8b76-a92fa2769ed7",
   "metadata": {},
   "source": [
    "**Nota**: Estas funciones están diseñadas para datos de corte transversal (cross-sectional) y no deben aplicarse directamente a series de tiempo. En el caso de las series de tiempo, se recomienda utilizar una ventana deslizante (rolling window) y, en lugar de eliminar datos, optar por métodos de estimación o interpolación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c25e31-dce3-453c-a83c-6cdf25801722",
   "metadata": {},
   "source": [
    "## Reporte general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a3c83-6efd-476d-9c3b-bcde547b2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quality_report(df):\n",
    "    \"\"\"\n",
    "    Genera un reporte básico de calidad de datos que incluye\n",
    "        - Dimensiones del DataFrame\n",
    "        - Tipos de datos por columna\n",
    "        - Cantidad de valores únicos por columna\n",
    "        - Estadísticas descriptivas para columnas numéricas\n",
    "    \"\"\"\n",
    "    print(\"\\nREPORTE DE CALIDAD DE DATOS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"Dimensiones del DataFrame: {df.shape}\")\n",
    "    print(f\"\\nTipos de datos:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Unique values per column\n",
    "    print(\"\\nValores únicos por columna:\")\n",
    "    for column in df.columns:\n",
    "        unique_count = df[column].nunique()\n",
    "        print(f\"{column}: {unique_count} valores únicos\")\n",
    "    \n",
    "    # Basic statistics for numeric columns\n",
    "    print(\"\\nEstadísticas básicas:\")\n",
    "    print(df.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bc1bc1-a659-47b6-99b1-ff8dd0dd341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reporte de calidad de datos\n",
    "generate_quality_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb6cac-b8a4-43f7-b922-4c1661a836cc",
   "metadata": {},
   "source": [
    "## Exportar datos (opcional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff54bb-1ce6-46dc-9b3f-a8f8f959c05c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Un dataframe lo podemos guardar con `df.to_excel('archivo.xlsx', index=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105dc65f-650c-4c21-af8d-388e4f1c96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta el dataframe depurado con el nombre 'output'\n",
    "# df.to_excel('output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae45e6-83ac-41d9-955a-7bb55f3e26e7",
   "metadata": {},
   "source": [
    "## Resumen del flujo de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9673b6-a08b-4b4b-bf29-5b959ecfbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archivo de origen\n",
    "#filepath = '../datasets/listings_cdmx.csv'\n",
    "url = 'https://github.com/adan-rs/AnalisisDatos/raw/main/datasets/listings_cdmx.csv'\n",
    "\n",
    "# Selección de datos\n",
    "df = load_and_filter(url)\n",
    "    \n",
    "# Eliminar filas duplicadas\n",
    "df = remove_duplicates(df)\n",
    "    \n",
    "# Manejar datos perdidos\n",
    "df = handle_missing_data(df)\n",
    "\n",
    "# Eliminar valores atípicos\n",
    "df = remove_outliers_iso_forest(df, columns=['price', 'minimum_nights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2c442-b5a1-4ea5-bbb4-27b5355db2fc",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "En un nuevo notebook, utiliza las funciones creadas y el flujo de trabajo para procesar los datos de Airbnb en otra ciudad. Por ejemplo, reemplaza el filepath por `'../datasets/listings_madrid.csv'` o el enlace (url) al archivo original por:  \n",
    "`'https://data.insideairbnb.com/spain/comunidad-de-madrid/madrid/2024-09-11/visualisations/listings.csv'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2bf36-d30f-4cb6-a9dc-967d97886a99",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- Una discusión interesante sobre el tratamiento de datos se puede encontrar en: Treiman, D. J. (2009). *Quantitative data analysis. Doing social research to test ideas*. San Francisco, CA: Jossey-Bass.\n",
    "- La base de datos fue tomada de https://insideairbnb.com/get-the-data/ para fines no comerciales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
