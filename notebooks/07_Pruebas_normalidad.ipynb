{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae05dff2-ab04-4236-97d9-031979e53134",
   "metadata": {},
   "source": [
    "# Pruebas de normalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027c0696-a2f4-4fb7-8bd7-6821f3500176",
   "metadata": {},
   "source": [
    "Antes de aplicar muchos de los métodos estadísticos (como la prueba t de Student o el ANOVA) es importante verificar si los datos siguien una distribución normal. La literatura especializada registra decenas de pruebas para evaluar la normalidad de los datos. Revisaremos los casos de la la prueba Shapiro-Wilk y la prueba Kolmogorov-Smirnov (con la corrección de Lilliefors). \n",
    "\n",
    "En las primeras dos pruebas (y otras más incluidas en este curso), vamos a crear funciones que realicen lo siguiente:\n",
    "1. *Preparar los datos*: Validar y procesar datos para la prueba.\n",
    "2. *Realizar la prueba estadística*: Obtener los estadísticos de prueva y valores p.\n",
    "3. *Mostrar los resultados e interpretación*: Para facilitar la descripción de los resultados de la prueba.\n",
    "4. *Guardar una conclusión general o el p-valor*: Para facilitar decisiones específicas en flujos automatizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984471df-d94c-4659-a6cf-71547352eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#df = pd.read_excel('../datas/enigh2020.xlsx')\n",
    "df = pd.read_excel('https://github.com/adan-rs/AnalisisDatos/raw/main/data/enigh2020.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0afc2-e9ae-4d4c-aa1f-bece3278c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para propósitos de ejemplo obtenemos una muestra de tamaño mediano\n",
    "data = df['edad_jefe'].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c46e67-68eb-4e53-9e96-73f554aab906",
   "metadata": {},
   "source": [
    "## Prueba Shapiro-Wilk\n",
    "*¿Para qué se utiliza?*\n",
    "La prueba de Shapiro-Wilk se emplea para evaluar si una muestra de datos proviene de una distribución normal. Es una de las pruebas más potentes para detectar desviaciones de la normalidad. \n",
    "\n",
    "*Variables consideradas:*\n",
    "Se aplica a una única variable cuantitativa (de razón o intervalo), cuyos valores se desean comparar contra una distribución normal teórica.\n",
    "\n",
    "*¿Cómo funciona?*\n",
    "La prueba calcula el estadístico W, que compara los valores observados con los que se esperaría bajo una distribución normal, utilizando una combinación lineal de los datos ordenados. El valor de W varía entre 0 y 1, donde un valor cercano a 1 indica que los datos son consistentes con una distribución normal.\n",
    "\n",
    "*Requisitos o supuestos:*\n",
    "- La variable debe ser cuantitativa y tener una escala continua o aproximadamente continua.\n",
    "- Las observaciones deben ser independientes.\n",
    "- Es más adecuada para muestras pequeñas o moderadas (originalmente diseñada para n < 50, pero se puede aplicar hasta n ≈ 2000).\n",
    "- Para muestras grandes, puede detectar pequeñas desviaciones de la normalidad que no son relevantes desde el punto de vista práctico. En tales casos, se recomienda complementar con métodos gráficos como histogramas, Q-Q plots o pruebas alternativas como Kolmogórov-Smirnov o Anderson-Darling.\n",
    "\n",
    "*Hipótesis planteadas:*\n",
    "- Hipótesis nula (H₀): Los datos provienen de una distribución normal.\n",
    "- Hipótesis alternativa (H₁): Los datos no provienen de una distribución normal.\n",
    "\n",
    "*Criterio de decisión:*\n",
    "Si el valor p asociado al estadístico W es menor que el nivel de significancia (por ejemplo, α = 0.05), se rechaza la hipótesis nula y se concluye que los datos no siguen una distribución normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8a602-3480-4c32-9517-9cca51cc4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def shapiro_wilk_test(data, alpha=0.05):\n",
    "    \"\"\" Aplica una prueba Shapiro-Wilk para evaluar la normalidad de los datos\"\"\"\n",
    "    statistic, p_value = stats.shapiro(data)\n",
    "    conclusion = \"no rechaza\" if p_value > alpha else \"rechaza\"\n",
    "    print(f'La prueba Shapiro-Wilk {conclusion} la normalidad de los datos (W = {statistic:.4f}, p = {p_value:.4f})')\n",
    "    return p_value > alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee95cec-14b5-4704-824b-60a34425a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = shapiro_wilk_test(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c4abd-931d-43cb-a45e-23bff095f8a8",
   "metadata": {},
   "source": [
    "Ejemplo de un reporte de resultados:\n",
    ">Se aplicó la prueba de normalidad de Shapiro-Wilk a los tiempos de entrega (en horas) de 50 pedidos realizados en la planta de distribución del norte del país. El valor de W fue de 0.942 y el valor-p asociado fue de 0.012, lo que indica que se rechaza la hipótesis nula de normalidad al nivel de significancia del 5%.\n",
    "Por lo tanto, se concluye que los tiempos de entrega no siguen una distribución normal, lo que sugiere la presencia de asimetrías o valores atípicos en el proceso logístico. Esto implica que para futuros análisis —como la construcción de intervalos de confianza o pruebas de hipótesis— deberán considerarse métodos no paramétricos o transformaciones adecuadas. Además, este hallazgo puede motivar una revisión de los procesos operativos que están generando variabilidad extrema o retrasos puntuales en las entregas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c766bb-8b5a-4b83-b8f2-b53e6a4a3686",
   "metadata": {},
   "source": [
    "## Prueba Kolmogorov-Smirnov-Lilliefors\n",
    "*¿Para qué se utiliza?*\n",
    "La prueba de Kolmogorov-Smirnov (K-S) se utiliza para evaluar si una muestra de datos cuantitativos sigue una distribución teórica específica (como la normal, exponencial o uniforme). Esta prueba es una herramienta general para comparar la forma de la distribución observada con una distribución acumulada esperada.\n",
    "Variables consideradas:\n",
    "Se aplica a una sola variable cuantitativa (de intervalo o razón) cuyos datos se desean contrastar con una distribución acumulativa específica.\n",
    "\n",
    "*¿Cómo funciona?*\n",
    "La prueba compara la función de distribución empírica (EDF) de los datos —es decir, la proporción acumulada de valores observados— con la función de distribución acumulada teórica (CDF). Calcula la máxima diferencia absoluta (estadístico D) entre ambas curvas. Cuanto mayor es esta diferencia, mayor es la evidencia contra la hipótesis de que los datos siguen la distribución especificada.\n",
    "\n",
    "*Requisitos o supuestos:*\n",
    "- La variable debe ser cuantitativa y continua.\n",
    "- Las observaciones deben ser independientes.\n",
    "- La prueba clásica supone que los parámetros de la distribución teórica (como la media y desviación estándar en el caso de la normal) son conocidos de antemano.\n",
    "- Si los parámetros se estiman a partir de la misma muestra, la prueba original no es estrictamente válida.\n",
    "\n",
    "*Corrección de Lilliefors:*\n",
    "Cuando los parámetros de la distribución normal se estiman desde los datos (caso típico en la práctica), se recomienda utilizar la prueba de Lilliefors, una modificación de la K-S diseñada para este caso. Esta corrección ajusta el valor crítico del estadístico para mantener la validez del contraste. En Python, puede aplicarse con la función lilliefors() de la biblioteca statsmodels.\n",
    "\n",
    "*Hipótesis planteadas:*\n",
    "- Hipótesis nula (H₀): Los datos provienen de la distribución teórica especificada.\n",
    "- Hipótesis alternativa (H₁): Los datos no provienen de esa distribución.\n",
    "\n",
    "*Criterio de decisión:*\n",
    "Se calcula el estadístico D, que representa la mayor diferencia entre la EDF y la CDF. Si el valor p asociado es menor que el nivel de significancia (por ejemplo, α = 0.05), se rechaza la hipótesis nula, concluyendo que los datos no siguen la distribución especificada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3512126e-63f4-414d-a7e2-8330379fbe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import lilliefors as sm_lilliefors\n",
    "\n",
    "def lilliefors_test(data, alpha=0.05):\n",
    "    \"\"\" Aplica una prueba Kolmogorov-Smirnov-Lilliefors para evaluar la normalidad de los datos\"\"\"  \n",
    "    statistic, p_value = sm_lilliefors(data)\n",
    "    conclusion = \"no rechaza\" if p_value > alpha else \"rechaza\"\n",
    "    print(f'La prueba de Lilliefors {conclusion} la normalidad de los datos (D = {statistic:.4f}, p = {p_value:.4f})')\n",
    "    return p_value > alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40a77a-2e78-4f72-8859-ea47997cc0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lilliefors_test(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e0d58-2e92-4119-997a-6620dc2ecd7a",
   "metadata": {},
   "source": [
    "Ejemplo de resultados:\n",
    ">Se aplicó la prueba de normalidad de Kolmogorov-Smirnov con corrección de Lilliefors a los tiempos de espera en el área de carga y descarga (en minutos) registrados durante 30 días hábiles consecutivos. El estadístico D fue de 0.176 y el valor-p correspondiente fue de 0.035, por lo que se rechaza la hipótesis nula de normalidad al nivel de significancia del 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585da2ba-3f4a-4cf0-a100-688e49b15dda",
   "metadata": {},
   "source": [
    "## Prueba Jarque-Bera\n",
    "La prueba Jarque-Bera (1980) evalúa cuanto se desvían el sesgo y la curtosis observados de los valores esperados bajo una distribución normal. Esta prueba fue desarrollada por el mexicano Carlos M. Jarque junto con Anil K. Bera.\n",
    "Las hipótesis son:\n",
    "- Hipótesis nula (H0): Los datos tienen una distribución normal.\n",
    "- Hipótesis alternativa (H1): Los datos no tienen una distribución normal.\n",
    "\n",
    "El estadístico Jarque-Bera (JB) sigue aproximadamente una distribución chi-cuadrada con dos grados de libertad asumiendo que la hipótesis nula es verdadera. Este estadístico se incluye en el reporte de resultados de la regresión lineal de la biblioteca de statsmodels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525363f-20ae-4db0-93ef-76c0ab2a3bfa",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html\n",
    "\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056b8f7-fe3c-4f5f-b619-3fc78706b4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
