{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01979842-6cf6-4e0a-8497-b95246285002",
   "metadata": {},
   "source": [
    "# Regresión logística\n",
    "\n",
    "*¿Para qué se utiliza?*\n",
    "La regresión logística se utiliza para modelar la probabilidad de ocurrencia de un evento binario, es decir, cuando la variable dependiente toma solo dos posibles valores (por ejemplo, 0 y 1, éxito o fracaso, compra o no compra). Es ampliamente empleada en contextos donde se desea predecir si algo sucederá o no, como en análisis de riesgo crediticio, diagnóstico médico, o comportamiento del consumidor.\n",
    "\n",
    "*Variables consideradas*\n",
    "- Variable dependiente: debe ser binaria (toma solo los valores 0 y 1).\n",
    "- Variables independientes: pueden ser cuantitativas o categóricas, y se utilizan para explicar o predecir la probabilidad del evento de interés.\n",
    "\n",
    "*¿Cómo funciona?*\n",
    "A diferencia de la regresión lineal, en la regresión logística no se modela directamente la variable dependiente, sino la probabilidad de que esta tome el valor de 1. Para evitar problemas como obtener probabilidades fuera del intervalo [0, 1], se utiliza una transformación llamada logit, que modela el logaritmo de la razón de probabilidades:\n",
    "\n",
    "ln⁡(p/(1-p))=β_0+β_1 X+...+β_q X_q\n",
    "\n",
    "Aquí, p representa la probabilidad de que el evento ocurra. Esta transformación permite que el lado izquierdo de la ecuación tome cualquier valor real, mientras que el lado derecho es una función lineal de las variables independientes.\n",
    "\n",
    "\n",
    "*Supuestos o requisitos principales*\n",
    "\n",
    "Aunque la regresión logística no requiere normalidad de los errores ni homocedasticidad, sí se basa en algunos supuestos importantes:\n",
    "- La relación entre las variables independientes y el logit de la probabilidad es lineal.\n",
    "- Independencia de las observaciones.\n",
    "- No debe haber multicolinealidad excesiva entre las variables independientes.\n",
    "- Tamaño de muestra adecuado, especialmente cuando las clases están desbalanceadas.\n",
    "\n",
    "*Evaluación de resultados*\n",
    "\n",
    "Una vez estimado el modelo, se calcula la probabilidad estimada para cada observación. Si esta probabilidad es mayor que un umbral (usualmente 0.5), se clasifica la observación como un \"1\" (evento ocurre); de lo contrario, como un \"0\".\n",
    "Adicionalmente, se pueden utilizar métricas como la razón de verosimilitud, pseudo R², curvas ROC, y matriz de confusión para evaluar el desempeño del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fc2d5-5758-47d0-8426-b93df8af6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Crear un conjunto de datos sintético\n",
    "data = pd.DataFrame({\n",
    "    'Ingresos': [25, 45, 28, 35, 40, 60, 22, 38, 50, 48],\n",
    "    'Edad':     [22, 35, 24, 32, 45, 52, 23, 41, 43, 36],\n",
    "    'Compra':   [0, 1, 0, 0, 1, 1, 0, 1, 1, 1]  # Variable binaria dependiente\n",
    "})\n",
    "\n",
    "# Variables independientes (X) y variable dependiente (y)\n",
    "X = data[['Ingresos', 'Edad']]\n",
    "y = data['Compra']\n",
    "\n",
    "# División en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Modelo de regresión logística\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predicción y evaluación\n",
    "y_pred = modelo.predict(X_test)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d69bc-6a90-40a5-a49c-01d205806c28",
   "metadata": {},
   "source": [
    "Observa que se realizó una división en conjunto de entrenamiento y prueba, esta división es fundamental para evaluar la capacidad de generalización del modelo. Si entrenamos y evaluamos sobre los mismos datos, podríamos obtener un modelo que se ajusta muy bien a esos datos específicos (sobreajuste), pero que no funciona bien con datos nuevos. Al separar un conjunto para prueba, podemos medir el rendimiento del modelo en datos no vistos.\n",
    "\n",
    "También se puede implementar una validación cruzada. En la validación cruzada, en lugar de usar solo una partición entrenamiento-prueba, la validación cruzada divide los datos en varios subconjuntos (k-folds). El modelo se entrena en k-1 folds y se evalúa en el restante, repitiendo el proceso k veces. Esto proporciona una mejor estimación de la capacidad del modelo para generalizar a nuevos datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437da0d-66fd-484b-99ef-a42ed8664bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar precisión con validación cruzada de 5 pliegues\n",
    "scores = cross_val_score(LogisticRegression(), X, y, cv=5, scoring='accuracy')\n",
    "print(f'Precisión promedio (validación cruzada 5-fold): {np.mean(scores):.2f}')\n",
    "print(f'Precisión por fold: {np.round(scores, 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ebaeb-6129-4fa5-a97c-7594f2fe9735",
   "metadata": {},
   "source": [
    "La matriz de confusión te permite ver cuántas observaciones fueron correctamente clasificadas (verdaderos positivos y negativos) y cuántas no. Para obtenerla utilizamos cross_val_predict que entrena y evalúa el modelo como en la validación cruzada, pero en lugar de calcular solo una métrica, genera predicciones para cada observación como si fueran nuevas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df10a2-c347-49e4-8c8e-df092693eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Obtener predicciones con validación cruzada (5 pliegues)\n",
    "y_pred_cv = cross_val_predict(LogisticRegression(), X, y, cv=5)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = confusion_matrix(y, y_pred_cv)\n",
    "\n",
    "# Mostrar la matriz de confusión de forma visual\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap='Blues')  # Opcional: cambia el color\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
