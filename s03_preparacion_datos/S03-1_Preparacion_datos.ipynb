{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc7a6a8-7b95-42a3-ae4d-1acce323a449",
   "metadata": {},
   "source": [
    "# Sesión 03: Preparación de datos\n",
    "*\"Es un error capital teorizar antes de tener datos. Sin darse cuenta, uno empieza a deformar los hechos para que se ajusten a las teorías, en lugar de ajustar las teorías a los hechos.\" Arthur Conan Doyle en \"Escándalo en Bohemia\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218eb4b-0951-493a-bb40-4349e0324eca",
   "metadata": {},
   "source": [
    "## 3.1 Selección de filas y columnas\n",
    "El archivo \"hoteles-vienna.xlsx\" contiene información de hoteles con habitaciones disponibles para cierto fin de semana. Aunque tenemos varias variables, solamente utilizaremos las siguientes:\n",
    "- hotel_id: es un identificador que reemplaza el nombre del hotel por razones de confidencialidad.\n",
    "- accommodationtype: tipo de hospedaje\n",
    "- price: precio.\n",
    "- center1distance: distancia al centro\n",
    "- starrating: calificación de 1 a 5 estrellas (más es mejor). \n",
    "- guestreviewsrating: calificación promedio otorgada por los clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147a8a4a-ad36-479a-968b-ef3a6b8dcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la biblioteca de pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98f1cf-f20e-47f8-9b4c-9aee8d8c4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"hotel_id\", \"accommodationtype\", \"price\", \"center1distance\",\n",
    "             \"starrating\", \"guestreviewsrating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9109c73-2b62-4e45-b2b9-5ccc4e131a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga el archivo 'data/b05a_hoteles-viena.xlsx'\n",
    "df = pd.read_excel('data/b05a_hoteles-viena.xlsx', usecols=variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68520d1-521e-43e4-b5cc-bdc790addfb6",
   "metadata": {},
   "source": [
    "La base de datos abarca diferentes tipos de hospedajes. Mediante `df['A'].value_counts()` podemos consultar qué categorías y frecuencias tiene una variable 'A' en un dataframe llamado 'df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf334d-208b-47a4-8282-bb522aceff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtén la frecuencia por tipo de hospedaje\n",
    "df['accommodationtype'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a29d0c-b29a-4dbb-9fa2-61ab9a0f1b93",
   "metadata": {
    "tags": []
   },
   "source": [
    "Selecciona solamente las filas que corresponden a hoteles. Por ejemplo: \n",
    "`df = df[df['accommodationtype'] == 'Hotel']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea9974-aa62-4168-8997-128341178740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona las filas correspondientes a hoteles\n",
    "df = df[df['accommodationtype'] == 'Hotel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0354dda-933d-474d-8ef9-537615d1ad6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Consulta la información de las variables con df.info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78d3fe-f1af-4033-b2c2-5d734b46c909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Revisa las primeras cinco filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121b10a-7c83-4249-bfe7-8b87bd3bb70c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.2 Datos duplicados\n",
    "En algunas ocasiones puede haber datos duplicados en nuestra base de datos. Para visualizar los datos duplicados podemos usar *duplicated()* de la siguiente manera:\n",
    "`df[df.duplicated()]`. Si nos interesa en la variable \"A\" en particular entonces es `df[df['A'].duplicated()]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228a140-5d4b-4a63-8b23-2a37b446f208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica los datos duplicados en todas las variables \n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e92d6-d878-41e0-b8dd-4920f6c1be90",
   "metadata": {},
   "source": [
    "Una opción para eliminar datos duplicados es usar *drop_duplicates()*. En nuestro ejemplo sería: `df.drop_duplicates()`. Esto sólo elimina observaciones filas duplicadas en todas las variables. De manera predeterminada, solamente conserva la primera fila de ellas.  \n",
    "En algunas ocasiones necesitaremos eliminar observaciones duplicadas en solamente algunas variables. En ese caso se puede agregar un listado con el argumento *subset*. En nuestro ejemplo: `df = df.drop_duplicates(subset=['hotel_id'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa32e0-3055-4ea9-bc91-aca0cbfe437b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Elimina las observaciones duplicadas\n",
    "df = df.drop_duplicates(subset=['hotel_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23ad92-68c6-452a-a868-418cf8fbb0e2",
   "metadata": {},
   "source": [
    "## 3.3 Datos perdidos\n",
    "En el caso de datos perdidos es importante determinar si se pueden considerar aleatorios o si existe un patrón que pueda afectar los resultados. En una encuesta, por ejemplo, es posible que las personas que prefieran no mencionar su ingreso tengan ciertas características, o bien, que las personas tiendan a no responder a preguntas sobre cierto tipo de comportamiento que no es socialmente aceptable.\n",
    "\n",
    "Es recomendable realizar pruebas estadísticas para verificar si los datos perdidos pueden ser considerados aleatorios o no. Bajo el procedimiento habitual, se construyen dos grupos, uno de observaciones con datos completos y otro grupo de observaciones con datos perdidos en una variable en particular. Posteriormente, se realizan pruebas para comparar si existen diferencias significativas en los valores promedio de las otras variables\n",
    "\n",
    "Como una aproximación inicial, el método `info()` puede servir para identificar qué variables tienen valores perdidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c7073-a004-496d-8f5a-be7d878acb2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica qué variables tienen valores perdidos con 'info()'\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227aa539-568d-49ab-bade-3a540aad237d",
   "metadata": {},
   "source": [
    "Para encontrar las filas con datos perdidos podemos usar `df[df.isna().any(axis=1)]`. El método *isna()* sirve para indicar qué valores son perdidos y el método *any* sirve para indicar qué filas tienen al menos un valor perdido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebbe088-d503-4be4-9b86-d2cc6657d89c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica qué observaciones tienen datos perdidos \n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085062f-edda-4284-8de7-1e80293166ce",
   "metadata": {},
   "source": [
    "*¿Qué hacer con datos perdidos?*  \n",
    "Los métodos más comunes para tratar con datos perdidos son:\n",
    "- Borrar filas o columnas con datos perdidos. Si son pocos datos perdidos (menos del 5%) y parecen ser completamente aleatorios, borrar los casos correspondientes es una alternativa.\n",
    "- Imputación simple: Reemplazar los datos perdidos con un valor calculado a partir de la misma variable. La opción más común y conservadora es utilizar el promedio. Sin embargo, este método es muy criticado debido a que reduce la variabilidad y afecta la estimación de los intervalos de confianza (Treiman, 2009).\n",
    "- Imputación multivariada: Reemplazar los datos perdidos con un valor calculado a partir de otras variables. En la imputación de datos por medio de la regresión se utilizan otras variables en la base de datos para establecer una ecuación de regresión en la que la variable dependiente es la variable con los datos perdidos. La ecuación de regresión estimada se utiliza para estimar los datos perdidos \n",
    "\n",
    "\n",
    "En cuanto a otros métodos de estimación se recomienda la lectura del capítulo “Multiple imputation of missing data” de Treiman (2009).\n",
    "\n",
    "\n",
    "*Imputación simple o univariada*  \n",
    "La imputación con la media para una columna 'A' es:  \n",
    "`df['A'] = df['A'].fillna(df['A'].mean())`  \n",
    "La imputación con la mediana es  \n",
    "`df['A'] = df['A'].fillna(df['A'].median())`   \n",
    "La imputación con la moda es:  \n",
    "`df['A'] = df['A'].fillna(df['A'].mode().iloc[0])` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784c00e-cd78-4d3e-979b-c1569edeb08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Consulta las variables que tienen datos perdidos con 'info()'\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe4b69-0127-4e4c-acc8-75c51bfb29a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reemplaza los valores perdidos con la media\n",
    "df['guestreviewsrating'] = df['guestreviewsrating'].fillna(df['guestreviewsrating'].mean())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700afed-7aa4-439e-8537-0253b6d94df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilizando 'describe()' obtén las principales medidas numéricas de resumen\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ff54bb-1ce6-46dc-9b3f-a8f8f959c05c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Un dataframe lo podemos guardar con `df.to_excel('carpeta/archivo.xlsx', index=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105dc65f-650c-4c21-af8d-388e4f1c96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta el dataframe depurado con el nombre 'output'\n",
    "df.to_excel('data/output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febcc66-3fb4-404d-afa3-ac0826c58a31",
   "metadata": {},
   "source": [
    "## 3.4 Valores atípicos\n",
    "Un valor atípico (outlier) es un valor extremo en una o más variables. En el caso de series univariadas, es común utilizar el método del valor z o el criterio del rango intercuartil. Para el caso de datos multivariados generalmente se utilizan criterios basados en la distancia de Mahalanobis y otras técnicas multivariadas. \n",
    "\n",
    "*¿Qué hacer con datos atípicos?*\n",
    "Si el valor extremo es un error de captura o parte de otra población lo recomendable es corregir o borrar el caso o variable. Si el valor extremo es parte de la distribución se debe mantener, pero se recomienda transformar la variable de forma tal que el valor extremo no impacte los resultados (p. ej. transformación logarítmica, transformación de Box-Cox o la recodificación de datos).\n",
    "\n",
    "*Método del valor z*\n",
    "En este enfoque un valor atípico es aquel que esté a más de tres desviaciones estándar a partir de la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d1042-ecea-49a2-a98c-21de5b1ab0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atipicos_3s(df, columna):\n",
    "    media = df[columna].mean()\n",
    "    desviacion_estandar = df[columna].std()\n",
    "    limite_superior = media + 3 * desviacion_estandar\n",
    "    limite_inferior = media - 3 * desviacion_estandar\n",
    "    df_filtrado = df[(df[columna] <= limite_inferior) | (df[columna] >= limite_superior)]\n",
    "    return df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14660a33-6385-4d59-a065-65b6d857f045",
   "metadata": {},
   "source": [
    "*(¿Cómo modificarías la función anterior para que arroje los datos depurados SIN valores atípicos?)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b971c0-8f65-4076-9dff-b62ee2056d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "atipicos_3s(df,'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb30c45-72a1-4144-b998-22f0eb4fc829",
   "metadata": {},
   "source": [
    "*Método del rango intercuartil*. Otro criterio común es considerar como atípicos los valores que están a más de 1.5 veces el rango intercuartil hacia el extremo a partir del 1er. o 3er. cuartil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6704f-a6e5-4373-a4e0-3f00a750887f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def atipicos_iqr(df, columna):\n",
    "    Q1 = df[columna].quantile(0.25)\n",
    "    Q3 = df[columna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    df_filtrado = df[(df[columna] <= limite_inferior) | (df[columna] >= limite_superior)]\n",
    "    return df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db7f53-c21d-40ff-a620-1a239f1fb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "atipicos_iqr(df, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2bf36-d30f-4cb6-a9dc-967d97886a99",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "Treiman, D. J. (2009). *Quantitative data analysis. Doing social research to test ideas*. San Francisco, CA: Jossey-Bass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9eecf5-4f53-4d57-bf2e-2b83d7acd4da",
   "metadata": {},
   "source": [
    "## Extra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82011522-197e-415b-b781-0426c18ea5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Crear y ajustar el modelo Isolation Forest\n",
    "clf = IsolationForest(contamination=0.1, random_state=42)\n",
    "clf.fit(df[['center1distance', 'price']])\n",
    "# Predecir los valores atípicos\n",
    "df['atipicos'] = clf.predict(df[['center1distance', 'price']])\n",
    "df_outliers = df[df['atipicos'] == -1]\n",
    "\n",
    "# Visualizar los datos y los valores atípicos detectados\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(df['center1distance'], df['price'], color='b', label='Datos normales', alpha=0.6)\n",
    "plt.scatter(df_outliers['center1distance'], df_outliers['price'], color='r', alpha=0.6)\n",
    "plt.xlabel('center1distance')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Detección de valores atípicos con Isolation Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4110eec-cd74-4261-a8e6-5643226badda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
