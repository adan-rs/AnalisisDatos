{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77143b4-62a7-47d5-ba7f-a508a9f1eee5",
   "metadata": {},
   "source": [
    "# Sesión 08: Análisis de regresión\n",
    "*\"Todos los modelos están equivocados, pero algunos son útiles\" G.E.P. Box (1919-2013)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5b02f-47a1-41d7-9988-e59525ccdaad",
   "metadata": {},
   "source": [
    "## ¿Qué es el análisis de regresión lineal?\n",
    "\n",
    "El análisis de regresión lineal es una técnica que se utiliza para pronosticar o explicar el comportamiento de una variable *dependiente* con relación a una o más variables *independientes*. En el área de negocios, la variable dependiente generalmente es la variable que nos interesa explicar o pronosticar (por ejemplo *ventas*), mientras que las variables independientes son aquellas que nos sirven para explicar (por ejemplo *gasto en publicidad*).\n",
    "\n",
    "Se asume que esta relación se ajusta a una ecuación lineal conocida como ecuación de regresión. Cuando sólo se tiene una variable independiente se conoce como regresión lineal simple: \n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x  + \\varepsilon\n",
    "$$\n",
    "El procedimiento más común para estimar esta ecuación de regresión es minimizando los errores al cuadrado en un método conocido como *mínimos cuadrados ordinarios*.\n",
    "\n",
    "Ejemplo: https://phet.colorado.edu/sims/html/least-squares-regression/latest/least-squares-regression_en.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ed06c-83e2-4c9a-bb0b-a4226070444a",
   "metadata": {},
   "source": [
    "## Interpretación de un modelo de regresión\n",
    "En su planteamiento básico la ecuación o modelo de regresión múltiple es la siguiente:\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 +...+ \\beta_k x_k + \\varepsilon\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $y$ es la variable dependiente.\n",
    "- $x$ es la variable independiente. Si solo existe una variable independiente se conoce como *regresión lineal simple*, si son dos o más, se llama *regresión lineal múltiple*.\n",
    "- $\\beta_0$ es el término de intersección (constante o intercepto), es el valor que tomaría $y$ si todas las variables fueran igual a cero (esto solo tiene sentido en algunos casos). \n",
    "- $\\beta_1$ es el coeficiente de regresión para cada $x$. Es el cambio estimado en la variable dependiente por unidad de cambio en la variable independiente, con todo lo demás constante.\n",
    "- $\\varepsilon$ es el término de error. Cuando corresponde al resultado de un modelo en específico es preferible referirse al error como *residual*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bee3b9-8e78-41ad-981b-3459e2a42f28",
   "metadata": {},
   "source": [
    "## Tamaño muestral\n",
    "Existen varias recomendaciones para determinar qué tamaño de muestra es adecuado. Para generalizar los resultados, lo mínimo recomendable son 5 observaciones por cada variable independiente, aunque lo deseable es tener de 15 a 20 observaciones por cada variable independiente  (Hair, Black, Babin, & Anderson, 2009).\n",
    "Green (1991) considera inadecuado establecer una constante (p. ej. 100 observaciones) pero sugiere que para evaluar un modelo se deben tener 50+8*k* observaciones, donde *k* es el número de variables independientes. Si se desea evaluar los coeficientes de regresión de cada variable recomienda 104+*k* observaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f33e7c-05e0-4b53-87e4-ce11867ef6d0",
   "metadata": {},
   "source": [
    "## Ajuste del modelo\n",
    "La métrica más utilizada para medir el ajuste del modelo es el *coeficiente de determinación* (R<sup>2</sup>) que mide la proporción de la variación de la variable dependiente que es explicada por el modelo. En un modelo de regresión lineal, la variación total de los datos  se mide con sumas de cuadrados:\n",
    "$$\n",
    "SS_{total} = SS_{modelo} + SS_{residual}\n",
    "$$\n",
    "Donde:\n",
    "\n",
    "$SS_{total} = \\sum_{i = 1}^{n} (y-\\bar{y})^2$ es la suma de cuadrados total  \n",
    "$SS_{modelo} = \\sum_{i = 1}^{n} (\\hat{y}-\\bar{y})^2$ es la suma de cuadrados del modelo también conocida como suma de cuadrados explicada  \n",
    "$SS_{residual} = \\sum_{i = 1}^{n} (y-\\hat{y})^2$ es la suma de cuadrados del residual o suma de cuadrados del error\n",
    "\n",
    "El coeficiente de determinación es equivalente a\n",
    "\n",
    "$$\n",
    "R^2 = SS_{modelo} / SS_{total}\n",
    "$$\n",
    "\n",
    "La R cuadrada toma valores entre 0 y 1, donde valores más grandes indican un mejor ajuste. Sin embargo, no existen criterios únicos de qué valor de R cuadrada es aceptable, sino que ello depende del área de estudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db781cb-3812-424a-ab90-1a61a2355e4b",
   "metadata": {},
   "source": [
    "## Supuestos básicos del modelo\n",
    "Las estimaciones de los coeficientes de regresión serán óptimas, de acuerdo al teorema de Gauss-Markov, si cumplen los siguientes supuestos con respecto al término de error:\n",
    "- El error sigue una distribución normal.\n",
    "- El error tenga media igual a cero.\n",
    "- Los errores son independientes (no están relacionados entre sí).\n",
    "- La varianza del error es constante.\n",
    "Esto se resume como que e~N<sub>iid</sub> (0,σ<sup>2</sup>). Si se cumplen estos supuestos, los estimadores serán los mejores estimadores insesgados de mínima varianza (*MELI* por las siglas en español; *BLUE* por las siglas en inglés). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d1ce90-c60e-40c6-8f2d-2f647e011d6b",
   "metadata": {},
   "source": [
    "## Homocedasticidad y normalidad\n",
    "Uno de los supuestos del modelo de regresión es que la varianza de los residuales se mantiene constante (homocedasticidad). El cumplimiento de este supuesto se puede explorar en la gráfica del residual estandarizado versus $\\hat{Y}$. Por ejemplo, un patrón de dispersión creciente (o decreciente) indicaría una violación a este supuesto.\n",
    "La normalidad en la distribución de los errores y su media se puede verificar en el histograma de los residuales y una prueba de normalidad (como Shapiro-Wilks o  Kolmogorov-Smirnov). En la prueba de normalidad lo deseable es obtener un p-valor mayor a 0.05 (no se rechaza la hipótesis nula de normalidad en los datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef4d76-7407-46c1-8ce1-58ee45bd9af5",
   "metadata": {},
   "source": [
    "## Independencia en los errores\n",
    "Los errores deben ser independientes en una regresión, esto es, no relacionados entre sí.  Generalmente esto implica evaluar la autocorrelación (correlación entre valores adyacentes) y se lleva a cabo mediante la prueba de Durbin-Watson (solamente en series de tiempo). En esta prueba, el estadístico de prueba puede tomar valores entre 0 y 4. Si el estadístico es cercano a 2 entonces los residuales no están correlacionados. Valores menores a 1 o mayores a 3 son señal de un problema serio de autocorrelación. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf3d4c-a8b9-423a-a3f5-765d8525601b",
   "metadata": {},
   "source": [
    "## Multicolinealidad\n",
    "La multicolinealidad se presenta cuando existe una fuerte correlación entre dos o más variables independientes. La multicolinealidad puede llevar a tener un modelo estadísticamente significativo, pero coeficientes de regresión no significativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a7dd7-b704-479b-a471-0dacaaae237c",
   "metadata": {},
   "source": [
    "## Variables categóricas\n",
    "En un análisis de regresión se pueden incluir variables categóricas. Si la variable categórica toma dos valores, se pueden codificar como una variable dicotómica con valores de “0” y “1”. La categoría que servirá de referencia se debe codificar como “0”. Si la variable categórica toma *k* valores se deben crear *k*-1 variables dicotómicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb39b7d-b985-4b83-b850-2daf742ad6d7",
   "metadata": {},
   "source": [
    "# Práctica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1d8c2-bf3e-4d1d-8632-fb37b55ee4e9",
   "metadata": {},
   "source": [
    "Utilizaremos un modelo de regresión para estimar el precio de una casa en una zona de la ciudad. Como primer paso importamos las bibliotecas a utilizar. En esta ocasión agregaremos la biblioteca `warnings` para evitar notificaciones de cambios futuros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c81ab0f-e96d-41be-b7f2-004dbfd364c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e9560-c096-4b7a-bdff-4b0e80d73cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el archivo \"data/b01_casas.xlsx\"\n",
    "df = pd.read_excel('data/b01_casas.xlsx')\n",
    "df = df[df['tipo']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4eef6-c3ec-4cce-bc2b-c1f244ac991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar las variables y el número de observaciones\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423a766-a9ea-4f98-9367-0dbe9f64d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar las primeras filas del DataFrame\n",
    "df.info(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abe409-e2fb-4986-af42-a6b59ab2986d",
   "metadata": {},
   "source": [
    "## Análisis descriptivo exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c90875-46da-4bce-8663-0250697edee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica las variables cuantitativasy obtener la estadística descriptiva\n",
    "var_cont = df[['preciomillones', 'recamaras', 'baños', 'construccion']]\n",
    "var_cont.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f3b5d-ad83-4bd9-a61d-21f6ced5875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la matriz de correlaciones\n",
    "var_cont.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a20da-7f51-483a-b9e6-8f6ee704a62c",
   "metadata": {},
   "source": [
    "La función `sns.pairplot`es útil para visualizar las relaciones entre pares de variables en un DataFrame. El primer parámetro indica el nombre del DataFrame, *corner* sirve para mostrar solo la matriz triangular inferior, *kind* permite indicar el tipo de gráfico (observa cómo cambia con 'reg' en vez de 'scatter'), *makers* se utiliza para indicar el tipo de marcas en el gráfico (observa cómo cambia con '+' en vez de '.'), y *height*  es la altura en pulgadas de cada gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedce80d-7381-47e3-afa2-03710a74070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos las relaciones entre variables\n",
    "sns.pairplot(var_cont, corner=True, kind='scatter', markers='.', height=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982cc9cc-c015-4c6c-ba75-37a6fd9c3e94",
   "metadata": {},
   "source": [
    "## Utilizando StatsModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e442de-5fba-41ef-9fa1-4786cc164aa4",
   "metadata": {},
   "source": [
    "Utilizaremos primero la biblioteca *StatsModel* para realizar el análisis de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192869a4-5990-4522-ad4f-6e4cf2d2a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librería\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6e283-7b43-4334-a3e5-ba86ff18a184",
   "metadata": {},
   "source": [
    "Es recomendable crear un dataframe 'X' con las variables independientes y otro \"y\" con la variable dependiente. Para seleccionar las variables independientes primero evalúa cuáles pueden ser relevantes. Cuando se tienen muchas variables independientes se puede realizar un *Análisis Factorial* para reducir la dimensionalidad. Para este ejemplo, empezaremos con la variable \"construcción\". La opción de StatsModel que utilizaremos, requiere crear una columna de \"1\" para representar la constante en el modelo de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d0946-3eb6-48b7-9810-44c980be8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con las v. indep. y la v. dependiente\n",
    "X = df[['construccion']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['preciomillones']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17189a3-8031-4625-a276-faa357b300c6",
   "metadata": {},
   "source": [
    "Corremos el modelo de regresión mediante mínimos cuadrados ordinarios:\n",
    "`regresion = sm.OLS(y, X).fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa88a18-69a5-4381-834a-3deafcd69f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad7579-04c4-4373-a693-41ae577d901a",
   "metadata": {},
   "source": [
    "El resultado se muestra con la instrucción\n",
    "`regresion.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c97f75-61ac-447c-829c-2f570cf146c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7093f596-2ed2-4047-84c0-7222bb956c0e",
   "metadata": {},
   "source": [
    "### Interpretación de los resultados\n",
    "- R-squared: entre más cercano a 1 es mejor\n",
    "- Adj. R-squared: se utiliza para comparar modelos con diferente número de variables independientes, debido a que la R cuadrada ajustada penaliza el incluir variables no significativas.\n",
    "- AIC / BIC: también se utilizan para comparar modelos de regresión múltiple, menos es mejor.\n",
    "- F-statistic: evalúa la significancia del modelo en conjunto, la hipótesis nula es que todos los coeficientes de regresión son iguales a cero.\n",
    "- Skew: o *sesgo* es una medida de la asimetría de la distribución\n",
    "- Kurtosis: indica qué tan \"puntiaguda\" o \"achatada\" es una distribución.\n",
    "- Prob(Omnibus): es una prueba para evaluar la normalidad en los residuales.\n",
    "- Jarque-Bera(JB) es un estadístico que sirve para evaluar la normalidad en los residuales.\n",
    "- Durbin-Watson: sirve para evaluar la presencia de autocorrelación. Valores entre 0 y 2 indican una autocorrelación positiva y valores entre 2 y 4 indican una autocorrelación negativa. Valores cercanos a 2 son deseables.\n",
    "- Cond. No. es el número de condición, que sirve para evalur problemas de multicolinealidad. Valores arriba de 30 se consideran problemáticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4e562-3389-40ff-a850-7c29192ca42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3daf0-5ee1-4137-bc60-913d926e7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuales = regresion.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4866b0-0c5f-4724-81fa-a69c8696e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regresion.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cbcd5-b446-4a82-92cb-5c2a891b2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_valores = [1,500]\n",
    "regresion.predict(nuevos_valores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2c9a0-a9ef-42b2-aee3-b05f399a5ea7",
   "metadata": {},
   "source": [
    "## Utilizando scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b489dc-b5de-4afc-9a06-49229a17d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la biblioteca\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23965f7a-fe53-453f-9976-26fef1d80a95",
   "metadata": {},
   "source": [
    "Con *SciKit-Learn' no se agrega la columna de constantes como en StatsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbb2df-316e-4cb1-a61a-ee132f86762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['construccion']]\n",
    "y = df['preciomillones']\n",
    "model = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d1a36-568b-4a7c-b8bc-8ae37e76483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los coeficientes de regresión\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee91ab2-166b-48cd-8a33-c58bad126867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener y estimada (y hat)\n",
    "y_hat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93b457-c105-43ee-bf1e-b53597cbea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener residuales\n",
    "residuales = (y - y_hat).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b15581-138d-447d-83ff-77a2ac1431be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular R cuadrada\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcddc95-c3c9-4dfa-a775-a2ee2339ad39",
   "metadata": {},
   "source": [
    "## Evaluación de supuestos\n",
    "### Multicolinealidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f83791-6d29-45b1-967b-dd0b5f188a3a",
   "metadata": {},
   "source": [
    "Para evaluar la multicolinealidad:\n",
    "- Revisar la matriz de correlaciones de las variables independientes para identificar correlaciones arriba de 0.90\n",
    "- Revisar el número de condición, valores mayores a 30 indicarían un problema grave\n",
    "- Calcular el Factor de Inflación de Varianza de cada variable, valores mayores a 10 indicarían un problema grave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8122b7f-e02a-42b6-b134-f73526ff4998",
   "metadata": {},
   "source": [
    "### Normalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058b8522-5c24-4866-a8d7-a9f36354e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(residuales, color='b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0576d-4d41-4ba8-a514-3dde6e87148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "stat, p_value = shapiro(residuales)\n",
    "print(\"Estadístico de prueba:\", stat)\n",
    "print(\"Valor p:\", p_value)\n",
    "\n",
    "# Interpretar los resultados\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Se rechaza la hipótesis nula de normalidad en los datos\")\n",
    "else:\n",
    "    print(\"No se puede rechazar la hipótesis nula de normalidad en los datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6dbc33-f71a-4dd9-9966-142e2cb7c522",
   "metadata": {},
   "source": [
    "### Homocedasticidad\n",
    "Existen varias pruebas que se pueden realizar para evaluar la presencia de heteroscedasticidad, tales como:\n",
    "- Breusch-Pagan: calcula la relación entre los residuales al cuadrado y las variables independientes, si la relación es significativa indica heteroscedasticidad..\n",
    "- Prueba de White: similar a la Breush-Pagan, considera la correlación serial.\n",
    "- Prueba de Goldfeld-Quandt: divide los datos con base en los valores de una variable independiente y compara las varianzas de los residuales en ambos grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e944acb-d891-45b1-bd1a-f726866117db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de residuales\n",
    "plt.scatter(y_hat, residuales, marker='.', color='b')\n",
    "plt.xlabel('y hat')\n",
    "plt.ylabel('residuales');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae04ceb-69e3-40b0-958f-4bc45e9bc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "\n",
    "X = df[['construccion']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['preciomillones']\n",
    "model = sm.OLS(y, X)\n",
    "resultado = model.fit()\n",
    "residuales = resultado.resid\n",
    "\n",
    "lm, lm_p_value, fvalue, f_p_value = het_breuschpagan(residuales, X)\n",
    "\n",
    "print(\"Estadístico LM:\", lm)\n",
    "print(\"Valor p del estadístico LM:\", lm_p_value)\n",
    "print(\"Estadístico F:\", fvalue)\n",
    "print(\"Valor p del estadístico F:\", f_p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc6723-b9f8-49b2-b9ad-d8df22fd1ceb",
   "metadata": {},
   "source": [
    "Si el p-valor es menor que 0.05 es evidencia de la presencia de heteroscedasticidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc9d6f-b415-4d24-9288-b63d920c57b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
